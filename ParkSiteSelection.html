<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Adam Ross Nelson JD PhD">
<meta name="dcterms.date" content="2025-01-01">
<meta name="keywords" content="reproducible research, data science methods, public policy, Wisconsin lakes, Python, Quarto">

<title>Applied Reproducible Data Science Processes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="ParkSiteSelection_files/libs/clipboard/clipboard.min.js"></script>
<script src="ParkSiteSelection_files/libs/quarto-html/quarto.js"></script>
<script src="ParkSiteSelection_files/libs/quarto-html/popper.min.js"></script>
<script src="ParkSiteSelection_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="ParkSiteSelection_files/libs/quarto-html/anchor.min.js"></script>
<link href="ParkSiteSelection_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="ParkSiteSelection_files/libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="ParkSiteSelection_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="ParkSiteSelection_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="ParkSiteSelection_files/libs/bootstrap/bootstrap-973236bd072d72a04ee9cd82dcc9cb29.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#literature-review" id="toc-literature-review" class="nav-link" data-scroll-target="#literature-review"><span class="header-section-number">2</span> Literature Review</a>
  <ul class="collapse">
  <li><a href="#policy-context" id="toc-policy-context" class="nav-link" data-scroll-target="#policy-context"><span class="header-section-number">2.1</span> Policy Context</a></li>
  <li><a href="#environmental-limnological-geologic" id="toc-environmental-limnological-geologic" class="nav-link" data-scroll-target="#environmental-limnological-geologic"><span class="header-section-number">2.2</span> Environmental Limnological Geologic</a></li>
  <li><a href="#the-data-science-process" id="toc-the-data-science-process" class="nav-link" data-scroll-target="#the-data-science-process"><span class="header-section-number">2.3</span> The Data Science Process</a></li>
  <li><a href="#dissemination-not-production" id="toc-dissemination-not-production" class="nav-link" data-scroll-target="#dissemination-not-production"><span class="header-section-number">2.4</span> Dissemination, Not Production</a></li>
  </ul></li>
  <li><a href="#data-method" id="toc-data-method" class="nav-link" data-scroll-target="#data-method"><span class="header-section-number">3</span> Data + Method</a>
  <ul class="collapse">
  <li><a href="#sec-wdnr-data" id="toc-sec-wdnr-data" class="nav-link" data-scroll-target="#sec-wdnr-data"><span class="header-section-number">3.1</span> WDNR Data</a></li>
  <li><a href="#preparation-for-analysis" id="toc-preparation-for-analysis" class="nav-link" data-scroll-target="#preparation-for-analysis"><span class="header-section-number">3.2</span> Preparation For Analysis</a></li>
  <li><a href="#exploratory-data-analysis" id="toc-exploratory-data-analysis" class="nav-link" data-scroll-target="#exploratory-data-analysis"><span class="header-section-number">3.3</span> Exploratory Data Analysis</a></li>
  <li><a href="#visual-exploratory-data-analysis" id="toc-visual-exploratory-data-analysis" class="nav-link" data-scroll-target="#visual-exploratory-data-analysis"><span class="header-section-number">3.4</span> Visual Exploratory Data Analysis</a></li>
  <li><a href="#binary-variable-exploration" id="toc-binary-variable-exploration" class="nav-link" data-scroll-target="#binary-variable-exploration"><span class="header-section-number">3.5</span> Binary Variable Exploration</a></li>
  <li><a href="#machine-learning-predictions-as-recommendations" id="toc-machine-learning-predictions-as-recommendations" class="nav-link" data-scroll-target="#machine-learning-predictions-as-recommendations"><span class="header-section-number">3.6</span> Machine Learning Predictions As Recommendations</a></li>
  <li><a href="#k-nearest-neighbors-knn" id="toc-k-nearest-neighbors-knn" class="nav-link" data-scroll-target="#k-nearest-neighbors-knn"><span class="header-section-number">3.7</span> k-Nearest Neighbors (KNN)</a></li>
  </ul></li>
  <li><a href="#analysis" id="toc-analysis" class="nav-link" data-scroll-target="#analysis"><span class="header-section-number">4</span> Analysis</a>
  <ul class="collapse">
  <li><a href="#train-test-split-procedure" id="toc-train-test-split-procedure" class="nav-link" data-scroll-target="#train-test-split-procedure"><span class="header-section-number">4.1</span> Train Test Split Procedure</a></li>
  <li><a href="#rescale-continuous-data" id="toc-rescale-continuous-data" class="nav-link" data-scroll-target="#rescale-continuous-data"><span class="header-section-number">4.2</span> Rescale Continuous Data</a></li>
  <li><a href="#fit-base-model" id="toc-fit-base-model" class="nav-link" data-scroll-target="#fit-base-model"><span class="header-section-number">4.3</span> Fit Base Model</a></li>
  <li><a href="#evaluate-search-for-optimal-k" id="toc-evaluate-search-for-optimal-k" class="nav-link" data-scroll-target="#evaluate-search-for-optimal-k"><span class="header-section-number">4.4</span> Evaluate + Search for Optimal K</a></li>
  <li><a href="#two-fold-cross-validation-symmetric-evaluation" id="toc-two-fold-cross-validation-symmetric-evaluation" class="nav-link" data-scroll-target="#two-fold-cross-validation-symmetric-evaluation"><span class="header-section-number">4.5</span> Two-fold cross-validation; Symmetric evaluation</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">5</span> Results</a>
  <ul class="collapse">
  <li><a href="#underserved-lakes" id="toc-underserved-lakes" class="nav-link" data-scroll-target="#underserved-lakes"><span class="header-section-number">5.1</span> Underserved Lakes</a></li>
  <li><a href="#overserviced-lakes" id="toc-overserviced-lakes" class="nav-link" data-scroll-target="#overserviced-lakes"><span class="header-section-number">5.2</span> Overserviced Lakes</a></li>
  </ul></li>
  <li><a href="#further-discussion" id="toc-further-discussion" class="nav-link" data-scroll-target="#further-discussion"><span class="header-section-number">6</span> Further Discussion</a>
  <ul class="collapse">
  <li><a href="#limitations-weaknesses" id="toc-limitations-weaknesses" class="nav-link" data-scroll-target="#limitations-weaknesses"><span class="header-section-number">6.1</span> Limitations + Weaknesses</a></li>
  <li><a href="#suggestions-for-further-work" id="toc-suggestions-for-further-work" class="nav-link" data-scroll-target="#suggestions-for-further-work"><span class="header-section-number">6.2</span> Suggestions For Further Work</a></li>
  </ul></li>
  <li><a href="#summary-conclusions" id="toc-summary-conclusions" class="nav-link" data-scroll-target="#summary-conclusions"><span class="header-section-number">7</span> Summary + Conclusions</a></li>
  <li><a href="#appendicies" id="toc-appendicies" class="nav-link" data-scroll-target="#appendicies"><span class="header-section-number">8</span> Appendicies</a></li>
  <li><a href="#scratch-space" id="toc-scratch-space" class="nav-link" data-scroll-target="#scratch-space"><span class="header-section-number">9</span> Scratch Space</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">10</span> References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="ParkSiteSelection.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li><li><a href="ParkSiteSelection.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Applied Reproducible Data Science Processes</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li></ul></div></div>
<p class="subtitle lead">A demonstration using data from Wisconsin lakes</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Adam Ross Nelson JD PhD <a href="mailto:arnelson3@wisc.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Wisconsin - Madison
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>This paper demonstrates a practical application of data science methods through a case study of Wisconsin lakes. This paper partially exibits an applied answer to a fundamental question in the field: how do data scientists provide value to organizations? Using a dataset of 16,711 lakes from the Wisconsin Department of Natural Resources, teh paper presents a reproducible workflow that supports policy makers in their oversight of public accommodations. This analysis closely follows reproducible research practices, making code, data, and methods openly available. This work not only provides practical insights for lake management but also serves as an educational template for understanding the data science process, from initial data exploration to final recommendations. The paper demonstrates how data scientists can bridge the gap between raw data and policy decisions, while maintaining transparency and reproducibility throughout the analytical process.</p>
  </div>
</div>

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>reproducible research, data science methods, public policy, Wisconsin lakes, Python, Quarto</p>
  </div>
</div>

</header>


<style>
.draft-watermark {
    position: fixed; top: 50%; left: 50%;
    transform: translate(-50%, -50%) rotate(-45deg);
    font-size: 100px; font-weight: bold; color: #FF0000; opacity: 0.1; }
</style>
<div class="draft-watermark">
INPROGRESS
</div>
<div id="bb2eda71-c685-403d-af4b-bbbb0306928b" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import Pandas, Seaborn, and related</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> geopandas <span class="im">as</span> gpd</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.image <span class="im">as</span> mpimg</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chi2_contingency</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown, display</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Set Seaborn context</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>sns.set_context(<span class="st">'paper'</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Preliminary data inspections</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>df0 <span class="op">=</span> pd.read_csv(<span class="st">'original_data/Lakes_Original.csv'</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'_variables.yml'</span>, <span class="st">'a'</span>) <span class="im">as</span> f:</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Write number of observations for later reference</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f'number_of_lakes: </span><span class="sc">{</span>df0<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Write number of records with 0°, 0° Latitude and Longitude</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f'zero_coords_count: </span><span class="sc">{</span>df0[df0[<span class="st">"Latitude"</span>] <span class="op">==</span> <span class="dv">0</span>]<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="808c42f7-e9cb-444c-878c-09339cdeff25" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="3">
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As provided by the Wisconsin Department of Natural Resrouces the data for this project includes 14 columns of information from 16711 lakes. <span class="citation" data-cites="wisconsin_dnr_lake_pages">(<a href="#ref-wisconsin_dnr_lake_pages" role="doc-biblioref">Wisconsin Department of Natural Resources 2024</a>)</span>.</p>
</div>
</div>
</div>
</div>
<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>A common question faced by organizational executive leadership (the c-suite), academic researchers, industry professionals, students, and others regarding data science methods or models is what do these methods and models accomplish. Closely related is what does a data scientist do? Or, how does a data scientist provide value to an organization? These are important questions becuase as <span class="citation" data-cites="raschka2019python">Raschka and Mirjalili (<a href="#ref-raschka2019python" role="doc-biblioref">2019</a>)</span> point out large companies “heavily invest in machine learning research applicaionts for <em>good reason</em>” (p.&nbsp;xiii) (emphasis added). This paper presents a novel response to those questions.</p>
<p>I write this paper for at least four audiences who all have a common interest.</p>
<ul>
<li>First for organizational leaders who may not seek to employ these methods on their own but who have an interest in developing or acquiring talent who can employ these methods.</li>
<li>Second, for academic researchers who are situated in universities, think takes, or research institues and who are often funded by private or government research grants.</li>
<li>Third, for industry professionals who may work in for-profit, not-for-profit, or governmental organizations.</li>
<li>And fourth for students, at any level of study but who may be newer to the exploration of data science.</li>
</ul>
<p>These audiences share a common interest in understanding the practical utility of data science methods and models. Each of thease audiences have a need to understand how data science can offer highly reproducible approaches, results, insights, utility, and other forms of valuable output. To assist in meeting these common objectives I also distribute with this paper its raw markdown, Python code, Jupyter notebooks, and data sources.</p>
<p>This paper presents an example of work that might have been performed by a data scientist who is working to support policy makers as they oversee the maintenance of public accommodations on lakes located across the State of Wisconsin. This paper’s example does not put a model into production because the contexts do not demand a model in production.</p>
<p>The guiding analytical question and goal for this paper is to use data science as a means to explore which lakes have public services such as a park, beach, or boat landing but perhaps should not. Conversely also to explore which lakes should have public services such as a park, breach, or boat landing but perhaps do not.</p>
<p>Those that have a service but perhaps should not I will describe as overserviced while those that do not have service but perhaps should I will describe as underserviced.</p>
</section>
<section id="literature-review" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Literature Review</h1>
<p>This literature review serves to provide an overview of three important contexts that inform this paper’s analytical approach including the policy context, the environmental/limnological/geologic context, and the practice of data science.</p>
<section id="policy-context" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="policy-context"><span class="header-section-number">2.1</span> Policy Context</h2>
<p>The goal of this project is to inform multiple autorities and decision makers as they work in collaboration to make and implement public policy. This context, where also multiple sources of authority conflict in their interests, may benefit from an analysis that identifies underserviced or overserviced lakes.</p>
<p>The management of Wisconsin’s lakes is a shared responsibility that involves state, local, and federal authorities, each contributing unique roles and expertise to ensure sustainable and effective oversight. <span class="citation" data-cites="garn2003why">Garn, Elder, and Robertson (<a href="#ref-garn2003why" role="doc-biblioref">2003</a>)</span> also point to lake management associations and lake districts as a source of authority, management, and oversight.</p>
<p>At the state level, the Wisconsin Department of Natural Resources (WDNR) serves as a key authority, providing a framework for lake management. The WDNR’s Lake Modeling Suite offers tools for assessing lake health and predicting management strategy outcomes, while the Surface Water Integrated Monitoring System (SWIMS) serves as a comprehensive database for water quality and ecological data <span class="citation" data-cites="wisconsin_dnr_lake_modeling_suite wisconsin_dnr_swims">(see <a href="#ref-wisconsin_dnr_lake_modeling_suite" role="doc-biblioref">Natural Resources Lake Modeling n.d.</a>; and <a href="#ref-wisconsin_dnr_swims" role="doc-biblioref">Natural Resources SWIMS Pages n.d.</a>)</span>. These resources are classic examples of those that data science practitioners would reference in executing a study with this study’s analytical goals.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Wisconsin Department of Natural Resources’ Surface Water Integrated Monitoring System (SWIMS) exemplifies the kind of data that data scientists often encounter in applied, policy-relevant contexts. Like many administrative and environmental datasets, SWIMS is rich with information but also characteristically messy. Analysts working with these or similar data must address missing values and inconsistencies in field formats, among other oddities. For example, some columns store numbers as strings due to the presence of unit labels (such as “43 FEET”), while others contain values outside the expected or valide ranges. Data of this kind demands both exploration and transformation before meaningful analysis can begin.</p>
</div>
</div>
<p>The state does not operate alone <span class="citation" data-cites="Thornton2013Stakeholder">(<a href="#ref-Thornton2013Stakeholder" role="doc-biblioref">Thornton 2013</a>)</span>. Local city and county authorities play a part in lake management, particularly in implementing localized policies that address specific community needs including whether to establish a park, beach, or boat access. For example, local governments often plan roads that would service the accommodations and oversee zoning law that would regulate which manner of development may be allowed in a given area.</p>
<p>Federal authorities also contribute to the management of Wisconsin’s lakes through regulatory and funding mechanisms. The federal Environmental Protection Agency (EPA) establishes water quality standards and provide financial support for restoration projects under the Clean Water Act <span class="citation" data-cites="Elbakidz2021hetero">(<a href="#ref-Elbakidz2021hetero" role="doc-biblioref">Elbakidze and Beeson 2021</a>)</span> and similar initiatives. Additionally, federally funded programs contribute to the preservation of critical habitats and mitigation of invasive species, which are pressing concerns for many of Wisconsin’s lakes.</p>
<p>In addition to state, local, and federal authorities, tribal governments play a role in the management and preservation of Wisconsin’s lakes <span class="citation" data-cites="Waller2018Ecology Spear2020Application">(<a href="#ref-Waller2018Ecology" role="doc-biblioref">Waller and Reo 2018</a>; and <a href="#ref-Spear2020Application" role="doc-biblioref">Spear et al. 2020</a>)</span>. Many of Wisconsin’s lakes are located on or near tribal lands, and the sovereign rights of indigenous nations give them a unique and essential role in overseeing natural resources. Tribal authorities often have deep, place-based knowledge and cultural ties to these waters, which guide stewardship practices <span class="citation" data-cites="Chief2014Engaging">(<a href="#ref-Chief2014Engaging" role="doc-biblioref">Chief, Meadow, and Whyte 2016</a>)</span>.</p>
<p>The overlapping jurisdictions and collaborative efforts among these levels of government underscore the complexity of lake management. For data scientists working in this domain, understanding the policy context is crucial for framing analytical questions, interpreting data, and ensuring that findings are actionable for stakeholders across all levels of governance. Because this analysis may inform policy decisions across various levels of government (state, local, tribal), the output of this analysis may be useful by many.</p>
</section>
<section id="environmental-limnological-geologic" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="environmental-limnological-geologic"><span class="header-section-number">2.2</span> Environmental Limnological Geologic</h2>
<p>As a study of Wisconsin lakes, this work intersects at least three major academic and scientific domains: environmental science, limnology, and geology. In practice a data scientist would heavily rely on literature and also consultations with experts who study, know, and understand these domains. Knowledge from literature and from consultation is commonly called “domain knowledge” among data science practitioners <span class="citation" data-cites="nelson2023confident">(<a href="#ref-nelson2023confident" role="doc-biblioref">Nelson 2023</a>)</span>. The ability to contextualize data is further emphasized by <span class="citation" data-cites="carvalho2024new">(<a href="#ref-carvalho2024new" role="doc-biblioref">Carvalho et al. 2024</a>)</span>, who notes that collaboration with domain experts is vital throughout the data science process to ensure that the results are relevant and actionable.</p>
<p>According to <span class="citation" data-cites="bendor2013modeling">BenDor et al. (<a href="#ref-bendor2013modeling" role="doc-biblioref">2013</a>)</span> the following factors figure into park development:</p>
<ul>
<li>Road and highway access: The accessibility of a lake by road or highway.</li>
<li>Proximity to public utilities: The availability of public utilities including electricity, septic, sewer, and similar.</li>
<li>Size and scope of the park: Larger parks with more complex infrastructure will take longer to plan and build.</li>
<li>Land acquisition: Acquiring land can be time-consuming, especially if it involves negotiations, legal proceedings, or eminent domain.</li>
<li>Environmental impact assessment: Environmental reviews and permits can add significant time to the process.</li>
<li>Funding: Securing funding for land acquisition, design, and construction can be a major hurdle and can delay the project.</li>
<li>Public input and approval: Public hearings and comment periods can extend the timeline, especially if there are significant concerns or opposition.</li>
<li>Construction timeline: The actual construction phase can vary depending on the complexity of the project, weather conditions, and other factors.</li>
</ul>
<p>Each of these domains contributes essential perspectives to understanding the complex systems governing lake ecosystems and their management.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Domain knowledge refers to the specialized understanding and expertise within a particular field or subject area. In the context of this study, domain knowledge spans environmental science, limnology, and geology—fields that provide the essential insights needed to analyze and interpret data about Wisconsin lakes. It allows data scientists to frame relevant questions, choose appropriate methodologies, and ensure that their findings are both accurate and actionable for decision-makers. <span class="citation" data-cites="nelson2023confident">(<a href="#ref-nelson2023confident" role="doc-biblioref">Nelson 2023</a>)</span>.</p>
</div>
</div>
<p>The environmental domain encompasses the broader ecological interactions affecting Wisconsin lakes. This ecology includes factors such as land use, agricultural, water quality, and climate changes. Limnology, the study of inland waters, focuses specifically on the biological, chemical, and physical characteristics of lakes and their surrounding environments. The geologic domain provides insights into the underlying structure and formation of Wisconsin’s lake basins.</p>
<p>The interplay of environmental, limnological, geologic (and other) factors defines the unique character of each lake. Effective policy and management decisions require an integrated understanding of these domains, supported by data-driven insights. By combining these perspectives, this study aims to model how a data science practitioner’s work necessarily involves reference to knowledge not specific to data science in collaboration with others.</p>
</section>
<section id="the-data-science-process" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="the-data-science-process"><span class="header-section-number">2.3</span> The Data Science Process</h2>
<blockquote class="blockquote">
<p>The goal of generating new knowledge is at the heart of all scientific disciplines, including data science. It is about finding patterns and relationships in the data that can help us make better decisions or solve complex problems. <span class="citation" data-cites="nelson2023confident">(<a href="#ref-nelson2023confident" role="doc-biblioref">Nelson 2023</a>, p 67)</span></p>
</blockquote>
<p>For a range of reasons data sciecne is also more “experimental” in its approaches <span class="citation" data-cites="Martins2021earlyprediction">(<a href="#ref-Martins2021earlyprediction" role="doc-biblioref">Martins et al. 2021</a>)</span> than more traditional inferential statistical work. For example, according to <span class="citation" data-cites="Martins2021earlyprediction">Martins et al. (<a href="#ref-Martins2021earlyprediction" role="doc-biblioref">2021</a>)</span> in regards to model or algorithm selection the best machine learning technique is dependent “on the dataset and on the formulation of the problem” (p.&nbsp;172). According to <span class="citation" data-cites="Breiman2001culture">Breiman (<a href="#ref-Breiman2001culture" role="doc-biblioref">2001</a>)</span> who described more traditional approaches as “data modeling” and the more experimental approahces as “algorithmic” modeling a key distinction between these two approaches is that for data modeling the main metric as to what may constitute a “good” model is a look at goodness of fit while the key metric for algorithmic modeling is predictive accuracy.</p>
<p><span class="citation" data-cites="Breiman2001culture">Breiman (<a href="#ref-Breiman2001culture" role="doc-biblioref">2001</a>)</span> defends so-called algorithmic modeling culture by suggesting that the focus among those in the data modeling culture have brewed an environment which has “lead to irrelevant theory,” “questionable scientific conclusions,” limited or stymied the use of “more sutiable agorithmic models,” and prevented work “on exciting new problems” (p.&nbsp;299-200).</p>
<p>A focus on accuracy is not a trivial distinction. The distiction underscores the practical utility of what <span class="citation" data-cites="Breiman2001culture">Breiman (<a href="#ref-Breiman2001culture" role="doc-biblioref">2001</a>)</span> refers to as algorithmic modeling in addressing complex problems. This paper’s research question, treated as a thought experiment, highlights the utility of prioritizing accuracy over measures like goodness of fit. Specifically, our goal is to produce two actionable lists of lakes:</p>
<ol type="1">
<li><strong>Overserviced Lakes</strong> Lakes that currently have public accommodations but perhaps should not. These will be lakes that our model incorrectly predicts as lacking public accommodations.</li>
<li><strong>Underserviced Lakes</strong> Lakes that lack public accommodations but perhaps should have them. These will be lakes that our model incorrectly predicts as having public accommodations.</li>
</ol>
<p>Thus, given this paper’s analytical question the results of interest will be incorrect predictions. The flexibility of data science and it’s algorithmic modeling culture permits a tailored approach finely tuned based on the needs of policymakers.</p>
<p>For instance, if policymakers prefer longer lists of lakes to consider, we can adjust the model through parameter tuning and feature selection to increase error rates, thereby expanding the lists. Conversely, if shorter, more focused lists are desired, we can optimize the model to reduce error rates.</p>
<p>Additionally, as this paper does, we can refine our approach by analyzing the probability of class membership rather than relying solely on binary predictions. A close look at probabilities permits further customization of list lengths to better meet policy objectives.</p>
<p>In order to solve the complex problem of deciding which lakes need more services and which lakes may have services but not need them, this paper explores patterns and relationships in Wisconsin Department of Natural Resources (WDNR) data by following the eight step data science process as documented by <span class="citation" data-cites="nelson2023confident">Nelson (<a href="#ref-nelson2023confident" role="doc-biblioref">2023</a>)</span> and reproduced here in <a href="#fig-data-sicence-process" class="quarto-xref">Figure&nbsp;1</a>. The paper’s new knowledge will be a list of lakes that are potentially overserviced along with another list of lakes that may be underserviced.</p>
<div id="cell-fig-data-sicence-process" class="cell" data-fig-num="true" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load image</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> mpimg.imread(<span class="st">'figures/process.png'</span>) </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the figure size (width, height in inches)</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span> <span class="op">*</span> <span class="fl">.5625</span>))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Display image</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-data-sicence-process" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-data-sicence-process-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ParkSiteSelection_files/figure-html/fig-data-sicence-process-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-data-sicence-process-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The data science process as published in <em>Confident Data Science</em> (Nelson, 2023).
</figcaption>
</figure>
</div>
</div>
</div>
<p>This process, as illustrated in <a href="#fig-data-sicence-process" class="quarto-xref">Figure&nbsp;1</a> starts at the upper left under the heading “Question or Problem” and moves clockwise as an interative cycle as it also further consists of the following:</p>
<ol type="1">
<li><strong>State an analytical question or a business problem to solve.</strong></li>
<li><strong>Look + check around.</strong> Explore if the question has been answered or if the problem has been solved. Also look to see what other similar questions or problems have been studied. Identify which methods have, or have not, been successful in the past. Also identify potential data sources.</li>
<li><strong>Justify the work.</strong> Examine the scope of the question or the problem. Determine how answering the question or solving the problem provides value. Determine what additional revenues or efficiencies an answer to the question or a solution to the problem may bring. If the question has previously been answered or the problem previously solved decide if now is a good time to replicate the work (Is there now new data? Or, are there now new methods available?)</li>
<li><strong>Wrangle the data.</strong> This involves finding, collecting, extracting, summarizing, validating, formulating, organizing, reshaping, coding, and recoding the data.</li>
<li><strong>Select and apply a method.</strong> Determine which methods will best answer the analytical question or solve the business problem and then apply those methods.</li>
<li><strong>Check and recheck.</strong> It is important to look back at this stage. Examine if the analytical question or business problem have been properly stated. Determine if there is new information that may have been missed, discounted, or overlooked in earlier stages. This stage may often involve seeking external input on in-progress work.</li>
<li><strong>Interpret the results.</strong> Here the process involves answering the original analytical question or proffering a solution to the specified business problem.</li>
<li><strong>Dissemination.</strong> The last stage involves either, or both disseminating the results or putting them into production.</li>
</ol>
</section>
<section id="dissemination-not-production" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="dissemination-not-production"><span class="header-section-number">2.4</span> Dissemination, Not Production</h2>
<p>This paper’s example does not exemplify putting a model into production. Below is further explanation as to why putting a model into production is not appropriate for this paper, and indeed the same is also true many papers using data science’s algorithmic mode of science.</p>
<p>This paper’s environmental/limnological/geologic contexts are a primary reason why the work here does not involve putting a model into production. A model in production is useful when a business systems, often driven by software systems, require a prediction that can serve as a tool in making a decision. Or in contexts when information is frequently or rapidly changing and the use case calls for using a prediction as a recommendation or an automated decision.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>A model in production is most useful in environments where predictions must be made repeatedly in response to rapidly changing data. These contexts often involve automated systems or decision-making pipelines—such as in weather forecasting, energy grid optimization, or real-time environmental monitoring—where data streams update frequently, and predictions must adapt continuously. For example, a model deployed in production for natural resources management might monitor streamflow or rainfall to inform automated alerts for flood risks or fire danger. In such cases, real-time data ingestion and dynamic model retraining are essential to the utility of the prediction.</p>
</div>
</div>
<p>A description of Wisconsin’s lakes from over fourty years ago remains as true today as it was when first published. <span class="citation" data-cites="lillie1983limnological">Lillie and Mason (<a href="#ref-lillie1983limnological" role="doc-biblioref">1983</a>)</span> describe the typical Wisconsin lake as “natural in origin, equally likely to be of seepage or drainage and stratified or mixed in basic lake type and probably located in the northern half ot the state” (p.&nbsp;N).</p>
<p>In the case of Wisconsin’s lakes it is not often that a new lake will appear on the map. According to data utilized in this paper’s analysis from the WDNR there are 16711 lakes located throughout the state of Wisconsin. The number of lakes has for decades frequently been reported at a rounded 15,000 (<span class="citation" data-cites="lillie1983limnological">Lillie and Mason (<a href="#ref-lillie1983limnological" role="doc-biblioref">1983</a>)</span>). The number of lakes in Wisconsin, or any geographic region, does not change often. Thus, in this case it is sufficient to train and test a model once on the existing data (which we do not expect to change often).</p>
</section>
</section>
<section id="data-method" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Data + Method</h1>
<p>As discussed above the method for this project involves a one-time analysis. Specifically the output will be a list of lakes that do have public accommodations but are more similar to lakes that do not have public accommodations (underserviced). A companion output will be a list of lakes that do not have public accommodations but that are more similar to lakes that do (overserviced).</p>
<p>Here I first discuss the data and then also the method that will produce a list of lakes that should be further considered for the addition of one or more public accommodation and a list of lakes that might benefit from public accommodation closure or retirement.</p>
<section id="sec-wdnr-data" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="sec-wdnr-data"><span class="header-section-number">3.1</span> WDNR Data</h2>
<p>The WDNR publishes the data for this analysis <span class="citation" data-cites="wisconsin_dnr_lake_pages">(<a href="#ref-wisconsin_dnr_lake_pages" role="doc-biblioref">Wisconsin Department of Natural Resources 2024</a>)</span>. The WDNR supports this data, uses it for a full range of purposes <span class="citation" data-cites="wisconsin_dnr_swims">(<a href="#ref-wisconsin_dnr_swims" role="doc-biblioref">Natural Resources SWIMS Pages n.d.</a>)</span>, and it receives contributions from “citizen science” initiatives <span class="citation" data-cites="kretschmann2011citizen">(<a href="#ref-kretschmann2011citizen" role="doc-biblioref">Kretschmann et al. 2011</a>)</span>.</p>
<div id="9d784769-f7d6-4155-a59c-c78434de0885" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df0.iloc[<span class="dv">5194</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>Waterbody ID Code (WBIC)                                              1605800
Lake Name                                                      Sevenmile Lake
Size (Acres)                                                            518.0
Official Max Depth                                                    43 FEET
Official Mean Depth                                                   19 FEET
Latitude                                                            45.879899
Longitude                                                          -89.051678
Public Landing                                                            Yes
Public Beach                                                               No
Public Park                                                               Yes
Fish Present                Musky, Panfish, Largemouth Bass, Smallmouth Ba...
Lake Type                                                            DRAINAGE
Water Clarity                                                        Moderate
County                                                         Oneida, Forest
Name: 5194, dtype: object</code></pre>
</div>
</div>
<div id="34ceb854-06df-4ecf-8311-2e09960187fb" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>characteristic_lake_id <span class="op">=</span> <span class="dv">5194</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'_variables.yml'</span>, <span class="st">'a'</span>) <span class="im">as</span> f:</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save characteristic lake name</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f'char_lake_name: </span><span class="sc">{</span>df0<span class="sc">.</span>iloc[characteristic_lake_id][<span class="st">"Lake Name"</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save characteristic lake size</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f'char_lake_size: </span><span class="sc">{</span>df0<span class="sc">.</span>iloc[characteristic_lake_id][<span class="st">"Size (Acres)"</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save characteristic lake max depth</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f'char_lake_max_depth: </span><span class="sc">{</span>df0<span class="sc">.</span>iloc[characteristic_lake_id][<span class="st">"Official Max Depth"</span>]<span class="sc">.</span>lower()<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save characteristic lake mean depth</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f'char_lake_mean_depth: </span><span class="sc">{</span>df0<span class="sc">.</span>iloc[characteristic_lake_id][<span class="st">"Official Mean Depth"</span>]<span class="sc">.</span>lower()<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save characteristic lake latitude</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f'char_lake_latitude: </span><span class="sc">{</span>df0<span class="sc">.</span>iloc[characteristic_lake_id][<span class="st">"Latitude"</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save characteristic lake longitude</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f'char_lake_longitude: </span><span class="sc">{</span>df0<span class="sc">.</span>iloc[characteristic_lake_id][<span class="st">"Longitude"</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save characteristic lake county</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f'char_lake_county: </span><span class="sc">{</span>df0<span class="sc">.</span>iloc[characteristic_lake_id][<span class="st">"County"</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A characteristic lake in this data is Sevenmile Lake which is about 518 in acres, up to 43 feet deep, (with a mean depth of 19 feet), and located at 45.8798989 latitude by -89.0516776 longitude in Oneida, Forest counties.</p>
<div id="5d979f47-c56e-4761-9fe0-10004ea3ae1b" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="7">
<p>This WDNR data features a high rate of missing data. A total of 6 of the data’s 14 columns contain some missing data. <a href="#fig-missing-data" class="quarto-xref">Figure&nbsp;2</a> displays missing data as bright lines in a heatmap. <a href="#tbl-missing-data" class="quarto-xref">Table&nbsp;1</a> shows the data’s 6 columns with at least some missing data. During data preparation, missing information for the <code>lake type</code>, and <code>water clarity</code> will be replaced with a new “missing” category. When creating a dummy array to represent the <code>fish present</code> column records with missing data will be represented by a set of <code>0</code> values. Missing data in the <code>Official Max Depth</code> column will be replaced with data that is a function of <code>Size (Acres)</code>. According to <span class="citation" data-cites="lillie1983limnological">Lillie and Mason (<a href="#ref-lillie1983limnological" role="doc-biblioref">1983, 4</a>)</span> a Wisconsin lake’s mean depth can be estimated as half of its maximum depth. Accordingly, missing information in the <code>Official Mean Depth</code> column will be replaced with 50% of each lake’s maximum depth.</p>
</div>
</div>
<div id="cell-fig-missing-data" class="cell" data-fig-num="true" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">3</span>))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>sns.set_context(<span class="st">'notebook'</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>sns.heatmap(df0.transpose().isna())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-missing-data" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-missing-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ParkSiteSelection_files/figure-html/fig-missing-data-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-missing-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Heat map showing missing data. Bright lines represent a mising data cell.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-tbl-num="true" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the proportion of missing entries in each column.</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>missing_table <span class="op">=</span> pd.DataFrame(</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    df0.isnull().mean(),</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Descriptively name the column</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">"Proportion of Missing Data In Each Column"</span>])</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter to columns with missing data</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>missing_table <span class="op">=</span> missing_table[</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    missing_table[<span class="st">'Proportion of Missing Data In Each Column'</span>] <span class="op">&gt;</span> <span class="dv">0</span>]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Add more descriptive text to the table columns</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>missing_table[</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="st">'Proportion of Missing Data In Each Column'</span>] <span class="op">=</span> missing_table[</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="st">'Proportion of Missing Data In Each Column'</span>].<span class="bu">apply</span>(</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: <span class="ss">f'</span><span class="sc">{</span><span class="bu">round</span>(x <span class="op">*</span> <span class="dv">100</span>, <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> % Missing Records'</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>missing_table</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="tbl-missing-data" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-tbl-num="true" data-execution_count="9">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-missing-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: The proportion of missing entries in each column. Columns with no missing data not shown.
</figcaption>
<div aria-describedby="tbl-missing-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Proportion of Missing Data In Each Column</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Official Max Depth</td>
<td>19.94 % Missing Records</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Official Mean Depth</td>
<td>90.18 % Missing Records</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Fish Present</td>
<td>70.76 % Missing Records</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Lake Type</td>
<td>62.24 % Missing Records</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Water Clarity</td>
<td>96.23 % Missing Records</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">County</td>
<td>8.71 % Missing Records</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
<p>Below <a href="#fig-wisconsin-lakes-mapped" class="quarto-xref">Figure&nbsp;3</a> shows the geographic distribution of lakes across Wisconsin. The lakes with a public beach, park, or boat landing show as dark <code>x</code> marks while the lakes with no public beach, park, or boat landing show as small <code>o</code> marks. Consistent with estimations from <span class="citation" data-cites="lillie1983limnological">Lillie and Mason (<a href="#ref-lillie1983limnological" role="doc-biblioref">1983</a>)</span> we see in <a href="#fig-wisconsin-lakes-mapped" class="quarto-xref">Figure&nbsp;3</a> that 50% of Wiscosin’s lakes are above north 45.5 degress latitude.</p>
<div id="cell-fig-wisconsin-lakes-mapped" class="cell" data-fig-num="true" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to fetch and save Wisconsin GeoJSON if not present</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fetch_wisconsin_geojson(local_path<span class="op">=</span><span class="st">"wisconsin.geojson"</span>, verbose<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(local_path):</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>local_path<span class="sc">}</span><span class="ss"> not found. Downloading..."</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        web <span class="op">=</span> <span class="st">'https://raw.githubusercontent.com/'</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        path <span class="op">=</span> <span class="st">'glynnbird/usstatesgeojson/master/'</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">file</span> <span class="op">=</span> <span class="st">'wisconsin.geojson'</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> requests.get(web <span class="op">+</span> path <span class="op">+</span> <span class="bu">file</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> <span class="bu">open</span>(local_path, <span class="st">'wb'</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>                <span class="bu">file</span>.write(response.content)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"Downloaded and saved </span><span class="sc">{</span>local_path<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>            fetch_error <span class="op">=</span> <span class="ss">f"Wisconsin GeoJSON fetch failed. "</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>            fetch_error <span class="op">+=</span> <span class="ss">f"HTTP status code: </span><span class="sc">{</span>response<span class="sc">.</span>status_code<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(fetch_error)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose: <span class="bu">print</span>(<span class="ss">f"Using local copy of </span><span class="sc">{</span>local_path<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> gpd.read_file(local_path)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Wisconsin GeoJSON</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>wisconsin <span class="op">=</span> fetch_wisconsin_geojson()</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean lake location data. Longitude sometimes stored as positive values.</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>lake_data <span class="op">=</span> df0[[<span class="st">'Latitude'</span>,<span class="st">'Longitude'</span>,</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>                <span class="st">'Public Landing'</span>,<span class="st">'Public Beach'</span>,</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>                <span class="st">'Public Park'</span>]].copy(deep<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>lake_data[<span class="st">'Longitude'</span>] <span class="op">=</span> [l <span class="cf">if</span> l <span class="op">&lt;</span> <span class="dv">0</span> <span class="cf">else</span> l <span class="op">*</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">for</span> l <span class="kw">in</span> lake_data[<span class="st">'Longitude'</span>]]</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove records recording 0 Latitude</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>lake_data <span class="op">=</span> lake_data[lake_data[<span class="st">'Latitude'</span>] <span class="op">&gt;</span> <span class="dv">0</span>]</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Make hue for color code</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>lake_data[<span class="st">'Landing, Beach, or Park'</span>] <span class="op">=</span> lake_data[</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'Public Landing'</span>,<span class="st">'Public Beach'</span>,<span class="st">'Public Park'</span>]].<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>lake_data[<span class="st">'Landing, Beach, or Park'</span>] <span class="op">=</span> [</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Has Public Services'</span> <span class="cf">if</span> i <span class="op">==</span> <span class="st">"Yes"</span> </span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> <span class="st">"Does Not Have Public Services"</span> <span class="cf">for</span> i <span class="kw">in</span> lake_data[<span class="st">'Landing, Beach, or Park'</span>]]</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert lake data to GeoDataFrame</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>gdf_lakes <span class="op">=</span> gpd.GeoDataFrame(</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    lake_data, geometry<span class="op">=</span>gpd.points_from_xy(lake_data.Longitude, lake_data.Latitude)</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure both GeoDataFrames use the same CRS</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>gdf_lakes.set_crs(epsg<span class="op">=</span><span class="dv">4326</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>wisconsin <span class="op">=</span> wisconsin.to_crs(epsg<span class="op">=</span><span class="dv">4326</span>)</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Wisconsin outline</span></span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>wisconsin.boundary.plot(ax<span class="op">=</span>ax, color<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">1.2</span>)</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot lake locations</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">'Longitude'</span>, y<span class="op">=</span><span class="st">'Latitude'</span>, data<span class="op">=</span>lake_data, ax<span class="op">=</span>ax,</span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">'Landing, Beach, or Park'</span>, style<span class="op">=</span><span class="st">'Landing, Beach, or Park'</span>,</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>    markers<span class="op">=</span>{<span class="st">'Does Not Have Public Services'</span>: <span class="st">'o'</span>, <span class="st">'Has Public Services'</span>: <span class="st">'X'</span>},</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>{<span class="st">'Does Not Have Public Services'</span>: <span class="st">'gray'</span>, <span class="st">'Has Public Services'</span>: <span class="st">'blue'</span>})</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Set plot labels and title</span></span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Lakes in Wisconsin from WDNR SWIMS Data'</span>)</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Longitude'</span>)</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Latitude'</span>)</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-wisconsin-lakes-mapped" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-wisconsin-lakes-mapped-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ParkSiteSelection_files/figure-html/fig-wisconsin-lakes-mapped-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wisconsin-lakes-mapped-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: A map showing the location of each lake in these data.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>To create a geographic visualization of Wisconsin’s lakes, this analysis overlays lake location data onto a geospatial outline of the state. The process relies on several essential tools and geospatial data formats, including GeoJSON, GeoPandas, and the use of a coordinate reference system (CRS) to ensure spatial consistency.</p>
<p>The geographic outline of Wisconsin is sourced from a publicly available GeoJSON file hosted on GitHub. GeoJSON is a widely used format for encoding geographic data structures using JSON (JavaScript Object Notation). It stores spatial features such as points, lines, and polygons along with associated attribute data. In this case, the polygon defining the boundary of the state of Wisconsin is used as a background layer in the final map.</p>
<p>I provide more thorough discussion of the processes and techniques for building this map visual in the appendicies.</p>
</div>
</div>
</section>
<section id="preparation-for-analysis" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="preparation-for-analysis"><span class="header-section-number">3.2</span> Preparation For Analysis</h2>
<p>The following procedure prepares this data for analysis. Starting with a fresh copy of the data from WDNR the code first reports a list of the existing column names and then creates a new set of column names that are more efficient to reference in code. When reviewing the first five columns it appears that max depth and mean depth are stored as strings and contain extraneous text (<code>"FEET"</code>) data. The code proceeds to remove that extraneous text and then converts the data type to float.</p>
<p>For a more efficient analysis the code then converts the <code>haslanding</code>, <code>hasbeach</code>, and <code>haspark</code> variables to binary where a <code>1</code> replaces the WDNR provided <code>Yes</code> value and a <code>0</code> replaces the WDNR provided <code>No</code> value. The code also creates a <code>hasservice</code> variable that is a composite which reports <code>1</code> if any of <code>haslanding</code>, <code>hasbeach</code>, or <code>haspark</code> are true and <code>0</code> otherwise. The <code>hasservice</code> variable will be the primary outcome variable in this analysis.</p>
<p>The code also inspects the <code>lat</code> and <code>long</code> data to discover that some values are out of the expected possible range. Wisconsin’s southwest corner is at approxaibately 42.5°N by 92.89°W while its northeast corner is at approxaimtely 47.1°N by 86.25°W. These lake data from WDNR include values in the <code>lat</code> and <code>long</code> columns beyond those ranges. As a preliminary step, where these WDNR data report positive longitude the anlaysis assumes that the intended value was negative to correspond with Wisconsin’s location in the western hemisphere. Upon converting the postive longitudinal data values to negative, the remaining non-zero values fall within the expected geographic range.</p>
<p>A total of 43 records reported 0°, 0° coordinates. The code also replaces these out of range 0°, 0° data with longitude and latitude values associated with each lake’s county coordinates from gigasheet.com. A small number of records contained no county data (or data from multiple counties) and thus the code drops these remaining records from the analysis.</p>
<p>The newly renamed <code>fish</code> column contains a comma separated list of fish species found in each lake. This column also contains a gramatically correct “and.” To convert these fish data to an array of dummy columns the code first replace the “and” with a comma via <code>pd.str.replace(' and',',', ')</code> and then uses <code>pd.str.get_dummies(sep=', ')</code>.</p>
<p>This code also manages missing data as described above in <a href="#sec-wdnr-data" class="quarto-xref">Section&nbsp;3.1</a> which describes the data as it was in its oroginal form from WDNR. Three extrememly large lakes in the .018th percential including Lake Winebago are removed. A final inspection of summary statistics is provided in <a href="#tbl-prepared-summary" class="quarto-xref">Table&nbsp;2</a>.</p>
<div id="c438935e-65b3-4b0a-8fd4-cf9b83950d63" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Start with a fresh copy of the data from WDNR</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'original_data/Lakes_Original.csv'</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>original_rows, original_cols <span class="op">=</span> df.shape</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Write original column and record shape for later reference</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">"_variables.yml"</span>, <span class="st">"a"</span>) <span class="im">as</span> f:</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f"original_rows_count: </span><span class="sc">{</span>original_rows<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f"original_cols_count: </span><span class="sc">{</span>original_cols<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Produce a list of columns</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Initial Column Set:'</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.columns, end<span class="op">=</span><span class="st">'</span><span class="ch">\n\n\n</span><span class="st">'</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename columns for quicker reference</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>df.columns <span class="op">=</span> [<span class="st">'ID'</span>,<span class="st">'name'</span>,<span class="st">'size'</span>,<span class="st">'maxdepth'</span>,</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>              <span class="st">'meandepth'</span>,<span class="st">'lat'</span>,<span class="st">'lon'</span>,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>              <span class="st">'haslanding'</span>,<span class="st">'hasbeach'</span>,<span class="st">'haspark'</span>,</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>              <span class="st">'fish'</span>,<span class="st">'type'</span>,<span class="st">'clarity'</span>,<span class="st">'county'</span>]</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Review sample of first 5 columns</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Sample, first five columns before modifications:'</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[df.columns[:<span class="dv">5</span>]].sample(<span class="dv">4</span>), end<span class="op">=</span><span class="st">'</span><span class="ch">\n\n\n</span><span class="st">'</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert maxdepth, meandepth to numberic</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'maxdepth'</span>] <span class="op">=</span> df[<span class="st">'maxdepth'</span>].<span class="bu">str</span>.replace(<span class="st">' FEET'</span>,<span class="st">''</span>).astype(<span class="st">'float'</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'meandepth'</span>] <span class="op">=</span> df[<span class="st">'meandepth'</span>].<span class="bu">str</span>.replace(<span class="st">' FEET'</span>,<span class="st">''</span>).astype(<span class="st">'float'</span>)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Find imputation function for maxdepth</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>maxdepth_imputation <span class="op">=</span> df[[<span class="st">'maxdepth'</span>,<span class="st">'size'</span>]].dropna()</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>maxdepth_imputation <span class="op">=</span> df[<span class="st">'maxdepth'</span>].mean() <span class="op">/</span> df[<span class="st">'size'</span>].mean()</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Tag records that had missing max depth</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'maxdepth_missing'</span>] <span class="op">=</span> (df[<span class="st">'maxdepth'</span>].fillna(<span class="dv">999999</span>) <span class="op">==</span> <span class="dv">999999</span>) <span class="op">*</span> <span class="dv">1</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply imputation function to missing maxdepth entries</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'maxdepth'</span>] <span class="op">=</span> df[<span class="st">'maxdepth'</span>].fillna(df[<span class="st">'size'</span>] <span class="op">*</span> maxdepth_imputation)</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Tag records that were missing meandepth</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'meandepth_missing'</span>] <span class="op">=</span> (df[<span class="st">'meandepth'</span>].fillna(<span class="dv">999999</span>) <span class="op">==</span> <span class="dv">999999</span>) <span class="op">*</span> <span class="dv">1</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply imputation function to missing meandepth entries</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'meandepth'</span>] <span class="op">=</span> df[<span class="st">'meandepth'</span>].fillna(df[<span class="st">'maxdepth'</span>] <span class="op">*</span> <span class="fl">.5</span>)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Print heading for notebook output</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Display excerpt of modified data.'</span>)</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Check results (first 5 columns)</span></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[df.columns[:<span class="dv">5</span>]].sample(<span class="dv">4</span>))</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Check results (next 5 columns)</span></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[df.columns[<span class="dv">5</span>:<span class="dv">10</span>]].sample(<span class="dv">4</span>))</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Check results (remaining columns)</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[df.columns[<span class="dv">10</span>:]].sample(<span class="dv">4</span>), end<span class="op">=</span><span class="st">'</span><span class="ch">\n\n\n</span><span class="st">'</span>)</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Dummy encode the 'haslanding','hasbeach','haspark' variables</span></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> [<span class="st">'haslanding'</span>,<span class="st">'hasbeach'</span>,<span class="st">'haspark'</span>]:</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>    df[col] <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> c <span class="op">==</span> <span class="st">"Yes"</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> c <span class="kw">in</span> df[col]]</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a composit hasservice variable</span></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'hasservice'</span>] <span class="op">=</span> df[[<span class="st">'haslanding'</span>,<span class="st">'hasbeach'</span>,<span class="st">'haspark'</span>]].<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert positive longitudinal values to negative</span></span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'lon'</span>] <span class="op">=</span> [l <span class="cf">if</span> l <span class="op">&lt;</span> <span class="dv">0</span> <span class="cf">else</span> l <span class="op">*</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">for</span> l <span class="kw">in</span> df[<span class="st">'lon'</span>]]</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace 0, 0 coordinates with county coordiantes from gigasheet.com</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>county_list <span class="op">=</span> pd.read_csv(<span class="st">'original_data/gigsheet-counties.csv'</span>)</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a county to lon mapper</span></span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>lon_map <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(county_list[<span class="st">'name'</span>], county_list[<span class="st">'lng'</span>]))</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a county to lon mapper</span></span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>lat_map <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(county_list[<span class="st">'name'</span>], county_list[<span class="st">'lat'</span>]))</span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the longitude mapper</span></span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'lon'</span>] <span class="op">=</span> pd.Series(np.where(</span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'lon'</span>] <span class="op">==</span> <span class="dv">0</span>, df[<span class="st">'county'</span>].<span class="bu">map</span>(lon_map), df[<span class="st">'lon'</span>])).fillna(<span class="dv">0</span>)</span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the latitude mapper</span></span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'lat'</span>] <span class="op">=</span> pd.Series(np.where(</span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'lat'</span>] <span class="op">==</span> <span class="dv">0</span>, df[<span class="st">'county'</span>].<span class="bu">map</span>(lat_map), df[<span class="st">'lat'</span>])).fillna(<span class="dv">0</span>)</span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove remaining records recording 0°, 0° coords (appox 7 records)</span></span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">'lat'</span>] <span class="op">&gt;</span> <span class="dv">0</span>]</span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove and replace extraneous "and" from fish column</span></span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'fish'</span>] <span class="op">=</span> df[<span class="st">'fish'</span>].<span class="bu">str</span>.replace(<span class="st">' and '</span>,<span class="st">', '</span>)</span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert fish to dummy array and join</span></span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.join(df[<span class="st">'fish'</span>].<span class="bu">str</span>.get_dummies(sep<span class="op">=</span><span class="st">', '</span>))</span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Discard original raw data</span></span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(<span class="st">'fish'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Create "Missing" category for nominal type and clarity</span></span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'type'</span>] <span class="op">=</span> df[<span class="st">'type'</span>].fillna(<span class="st">'Missing'</span>)</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'clarity'</span>] <span class="op">=</span> df[<span class="st">'clarity'</span>].fillna(<span class="st">'Missing'</span>)</span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Count number of lakes with m ore than 20,000 acres</span></span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"There are </span><span class="sc">{</span><span class="bu">len</span>(df[df[<span class="st">'size'</span>] <span class="op">&gt;</span> <span class="dv">20000</span>])<span class="sc">}</span><span class="ss"> lakes greater than 20,000 acres"</span>)</span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove lakes more than 20,000 acres</span></span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">'size'</span>] <span class="op">&lt;</span> <span class="dv">20000</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exploratory-data-analysis" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="exploratory-data-analysis"><span class="header-section-number">3.3</span> Exploratory Data Analysis</h2>
<p>Exploratory Data Analysis (EDA) serves as a critical bridge between raw data and later more formal analysis and data modeling. This EDA is the stage at which a scientist engages directly with data to uncover initial patterns, surface anomalies, identify missing values, and begin assessing the structure and relationships among variables. <span class="citation" data-cites="gutman2021becoming">Gutman and Goldmeier (<a href="#ref-gutman2021becoming" role="doc-biblioref">2021</a>)</span> describe exploratory data analysis as “an ongoing process” (p.&nbsp;52). Thus EDA is not merely a preliminary step, but rather a dynamic and iterative component of the broader data science workflow. This ongoing process allows the analyst to refine questions, revisit assumptions, and incrementally develop insight into the nature and quality of the data.</p>
<p>As <span class="citation" data-cites="nelson2023confident">Nelson (<a href="#ref-nelson2023confident" role="doc-biblioref">2023</a>)</span> notes, “without at least some preparation, an exploratory analysis might reveal less than fully useful insights. Simultaneously, without at least some exploration it is not fully possible to know what preparation will be necessary before a full analysis” (p.&nbsp;85). This is a <em>which comes first</em> problem; a proverbial <em>chicken or egg</em> question. For example, in this paper a handful of data manipulations have already been described and executed above, all of which required at least some exploration. Proper execution of EDA early and often through the course of a project guides both data preparation and the analysis along the way. Below is a more formal and analytical exploration of the data aimed at understanding which features may be useful in a predictive algorithm.</p>
<div class="cell" data-tbl-num="true" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preserve summary statistics for later reference in the appendix</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>summary_stats_appendix <span class="op">=</span> df.drop(</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'ID'</span>,<span class="st">'haslanding'</span>,<span class="st">'hasbeach'</span>,<span class="st">'haspark'</span>], </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    axis<span class="op">=</span><span class="dv">1</span>).describe().<span class="bu">round</span>(<span class="dv">3</span>).transpose().drop([<span class="st">'25%'</span>,<span class="st">'75%'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>summary_stats <span class="op">=</span> df.drop(</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'ID'</span>,<span class="st">'haslanding'</span>,<span class="st">'hasbeach'</span>,<span class="st">'haspark'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>summary_has <span class="op">=</span> summary_stats[</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    summary_stats[<span class="st">'hasservice'</span>] <span class="op">==</span> <span class="dv">1</span>].describe().transpose()[</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        [<span class="st">'mean'</span>,<span class="st">'std'</span>]]</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>summary_has_n <span class="op">=</span> summary_stats[summary_stats[<span class="st">'hasservice'</span>]<span class="op">==</span><span class="dv">1</span>].shape[<span class="dv">0</span>]</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>summary_has_not <span class="op">=</span> summary_stats[</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    summary_stats[<span class="st">'hasservice'</span>] <span class="op">==</span> <span class="dv">0</span>].describe().transpose()[</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        [<span class="st">'mean'</span>,<span class="st">'std'</span>]]</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>summary_has_not_n <span class="op">=</span> summary_stats[summary_stats[<span class="st">'hasservice'</span>]<span class="op">==</span><span class="dv">0</span>].shape[<span class="dv">0</span>]</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>summary_all <span class="op">=</span> summary_stats.describe().transpose()[</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'mean'</span>,<span class="st">'std'</span>]]</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>summary_all_n <span class="op">=</span> summary_stats.shape[<span class="dv">0</span>]</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>summary_stats_final <span class="op">=</span> pd.concat([summary_has, summary_has_not, </span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>           summary_all], axis<span class="op">=</span><span class="dv">1</span>, </span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>           keys<span class="op">=</span>[<span class="ss">f'Has Service n=</span><span class="sc">{</span>summary_has_n<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>                 <span class="ss">f'No Service n=</span><span class="sc">{</span>summary_has_not_n<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>                 <span class="ss">f'Pooled Stats n=</span><span class="sc">{</span>summary_all_n<span class="sc">}</span><span class="ss">'</span>])</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>summary_stats_final.drop([<span class="st">'hasservice'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="tbl-prepared-summary" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-tbl-num="true" data-execution_count="12">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-prepared-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Summary statistics following data preparation.
</figcaption>
<div aria-describedby="tbl-prepared-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="12">
<div>


<table class="dataframe do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">Has Service n=5412</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">No Service n=11289</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">Pooled Stats n=16701</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">size</td>
<td>126.103186</td>
<td>620.251559</td>
<td>15.566853</td>
<td>72.814624</td>
<td>51.386422</td>
<td>361.816980</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">maxdepth</td>
<td>18.030048</td>
<td>34.543742</td>
<td>10.388841</td>
<td>15.992963</td>
<td>12.864993</td>
<td>23.922990</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">meandepth</td>
<td>8.347434</td>
<td>16.790334</td>
<td>5.121726</td>
<td>7.871674</td>
<td>6.167024</td>
<td>11.640702</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">lat</td>
<td>45.362475</td>
<td>0.960428</td>
<td>45.195551</td>
<td>0.960455</td>
<td>45.249643</td>
<td>0.963590</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">lon</td>
<td>-90.031606</td>
<td>1.301074</td>
<td>-90.318745</td>
<td>1.356957</td>
<td>-90.225697</td>
<td>1.345791</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">maxdepth_missing</td>
<td>0.105876</td>
<td>0.307707</td>
<td>0.243954</td>
<td>0.429484</td>
<td>0.199210</td>
<td>0.399418</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">meandepth_missing</td>
<td>0.772358</td>
<td>0.419349</td>
<td>0.963770</td>
<td>0.186870</td>
<td>0.901742</td>
<td>0.297672</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Catfish</td>
<td>0.013304</td>
<td>0.114583</td>
<td>0.002480</td>
<td>0.049743</td>
<td>0.005988</td>
<td>0.077150</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Largemouth Bass</td>
<td>0.407428</td>
<td>0.491401</td>
<td>0.148729</td>
<td>0.355837</td>
<td>0.232561</td>
<td>0.422477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Musky</td>
<td>0.097746</td>
<td>0.296998</td>
<td>0.016831</td>
<td>0.128642</td>
<td>0.043051</td>
<td>0.202979</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Northern Pike</td>
<td>0.296748</td>
<td>0.456867</td>
<td>0.084418</td>
<td>0.278027</td>
<td>0.153224</td>
<td>0.360214</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Panfish</td>
<td>0.445122</td>
<td>0.497025</td>
<td>0.180087</td>
<td>0.384277</td>
<td>0.265972</td>
<td>0.441863</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Smallmouth Bass</td>
<td>0.092018</td>
<td>0.289078</td>
<td>0.017628</td>
<td>0.131600</td>
<td>0.041734</td>
<td>0.199987</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Sturgeon</td>
<td>0.007761</td>
<td>0.087759</td>
<td>0.000443</td>
<td>0.021042</td>
<td>0.002814</td>
<td>0.052976</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Trout</td>
<td>0.060791</td>
<td>0.238968</td>
<td>0.019311</td>
<td>0.137621</td>
<td>0.032753</td>
<td>0.177994</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Walleye</td>
<td>0.161493</td>
<td>0.368019</td>
<td>0.026220</td>
<td>0.159797</td>
<td>0.070056</td>
<td>0.255248</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
<p><strong>TODO: Add remaining columns to this table. See page 20ish.</strong></p>
<p><a href="#tbl-prepared-summary" class="quarto-xref">Table&nbsp;2</a> presents summary statistics for these lakes data from the WDNR, segmented by whether or not the lake has public services (boat landing, beach, or park). The table reports the mean and standard deviation for each variable within both groups in the left and middle columns, along with pooled overall statistics on the two far right columns. This table provides a summary that can assist in evaluating which variables may serve as useful predictors in classifying or predicting whether a lake has public services.</p>
<p>For example, lakes with public services are, on average, much larger than lakes without services (126.1 vs.&nbsp;15.6 acres), and the pooled mean is 51.4 acres. The standard deviation is also substantially higher among lakes with services, reflecting greater variability in size. This difference suggests that lake size may be a strong candidate as a predictive variable, with larger lakes being much more likely to have public accommodations. Similarly maximum depth (maxdepth), mean depth (meandepth), along with the presence of some fish speacies may also offer predictive value.</p>
<div id="122cff90-c4dd-4249-b8dc-affdc359def6" class="cell" data-execution_count="13">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="13">
<p>The final data set consists of 16701 records and 25 columns; there are no missing data. The primary target in this paper’s analysis is whether the lake has a public service such as a boat landing, beach, or park. Approximately 32.41% of these lakes have at least one public service.</p>
</div>
</div>
</section>
<section id="visual-exploratory-data-analysis" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="visual-exploratory-data-analysis"><span class="header-section-number">3.4</span> Visual Exploratory Data Analysis</h2>
<p>To explore how each variable may predict the presence of a public service on any of Wisconsin’s lakes I produce series of categorical violine plots in <a href="#fig-violin-plot" class="quarto-xref">Figure&nbsp;4</a>. This figure further illustrats how the presence of public services such as boat landings, beaches, or parks may relate to five continuous features of each lake: size, maximum depth, mean depth, latitude, and longitude. Each plot shows the distribution of these features’ natural log values for lakes with and without public services.</p>
<div id="cell-fig-violin-plot" class="cell" data-fig-num="true" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid of subplots</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">20</span>),</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    ncols<span class="op">=</span><span class="dv">1</span>, nrows<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    squeeze<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten() <span class="cf">if</span> <span class="bu">isinstance</span>(axes, np.ndarray) <span class="cf">else</span> [axes]</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust the spacing between the subplots</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(hspace<span class="op">=</span><span class="fl">0.5</span>, wspace<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Tuple list of var names and titles</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>variables <span class="op">=</span> [</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'size'</span>, <span class="st">'Size in acres'</span>),</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'maxdepth'</span>, <span class="st">'Maximum lake depth'</span>),</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'meandepth'</span>, <span class="st">'Mean lake depth'</span>),</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'lat'</span>, <span class="st">'Latitude location'</span>),</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'lon'</span>, <span class="st">'Longitude Location'</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through list of variables and titles</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (var, title) <span class="kw">in</span> <span class="bu">enumerate</span>(variables):</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    sns.violinplot(data<span class="op">=</span>df, x<span class="op">=</span>np.log(np.<span class="bu">abs</span>(df[var])), </span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>                   y<span class="op">=</span><span class="st">'hasservice'</span>, orient<span class="op">=</span><span class="st">'h'</span>, </span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>                   ax<span class="op">=</span>axes[i])</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f'</span><span class="sc">{</span>title<span class="sc">}</span><span class="ss"> (Fig 4</span><span class="sc">{</span><span class="st">"abcde"</span>[i]<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(<span class="ss">f'Natural log of </span><span class="sc">{</span>var<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="ss">f'Yes  (Has Service)  No'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-violin-plot" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-violin-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ParkSiteSelection_files/figure-html/fig-violin-plot-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-violin-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Violin plots exploring how the presence of services differentiate by continuous variables from the WDNR data.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Specifically lake size, maximum depth, and mean depth, the top three plots in <a href="#fig-violin-plot" class="quarto-xref">Figure&nbsp;4</a> show differences between lakes that do and do not have public services. In each of these cases, lakes with services (in orange) tend to be shifted to the right along the x-axis, meaning they are generally larger and deeper than lakes without services (in blue). Not only are the central tendencies higher for lakes with services, but the spread of values is also wider, particularly for size, suggesting a greater diversity in lake sizes among serviced lakes. These differences imply that lake size and depth may be strong predictors for whether a lake has public services.</p>
<p>On latitude and longitude, the bottom two plots of <a href="#fig-violin-plot" class="quarto-xref">Figure&nbsp;4</a>, show less pronounced differences. There is modest separation in the distributions for lakes with and without services, particularly in latitude, where lakes with public services appear to be slightly more concentrated in certain geographic bands. This may reflect regional planning priorities or population density factors but likely provides less predictive value than physical lake characteristics.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The continuous variables displayed in Figure 4 have long-tailed, highly-skewed distributions. To make the visualizations more interpretable and to reduce the influence of extreme values, I applied the natural logarithm transformation. This common transformation compresses the scale of larger values. The result is a more readable distribution.</p>
</div>
</div>
<p>These visual explorations serve as an important visual check on the potential predictive power of each feature when modeling the presence of public service. The greater the separation between the two distributions, the more likely that variable will be useful in a classification task. Based on the WDNR data, features like size, max depth, and mean depth appear to have strong potential as predictors, while latitude and longitude may contribute some additional nuance when combined with other variables.</p>
<p>One additional customary plot used in exploratory data anlysis is the pair plot. Below <a href="#fig-logpairplot_1" class="quarto-xref">Figure&nbsp;5</a> again reveals the same patterns noted above in <a href="#tbl-prepared-summary" class="quarto-xref">Table&nbsp;2</a> and <a href="#fig-violin-plot" class="quarto-xref">Figure&nbsp;4</a>.</p>
<div id="cell-fig-logpairplot_1" class="cell" data-fig-num="true" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Produce a filtered pairplot excluding observations that had missing max depth</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>log_pairplot <span class="op">=</span> sns.pairplot(</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    df[(df[<span class="st">'maxdepth_missing'</span>] <span class="op">!=</span> <span class="va">True</span>) <span class="op">&amp;</span> (df[<span class="st">'meandepth_missing'</span>] <span class="op">!=</span> <span class="va">True</span>)]</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    [[<span class="st">'size'</span>,<span class="st">'maxdepth'</span>,<span class="st">'meandepth'</span>,<span class="st">'hasservice'</span>]],</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">'hasservice'</span>, aspect<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> log_pairplot.axes.flatten():  <span class="co"># Iterate over all subplots</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    ax.set_xscale(<span class="st">'log'</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    ax.set_yscale(<span class="st">'log'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-logpairplot_1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-logpairplot_1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ParkSiteSelection_files/figure-html/fig-logpairplot_1-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-logpairplot_1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: A Traditional Pairplot.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="binary-variable-exploration" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="binary-variable-exploration"><span class="header-section-number">3.5</span> Binary Variable Exploration</h2>
<p>These WDNR data also consist of multiple columns of a binary nature, reporting the presence of specific fish species including catfish, largemouth bass, musky, northern pike, panfish, smallmouth bass, sturgeon, trout, and walleye. Instead of exploring the potential predictive value of these binary with violin plots we must turn to other options such as chi square analysis which is well suited to test the whether the presence of a publice service may be a function of the presence of any given species.</p>
<div id="a9179adb-6d2f-43b9-8179-048bc5bfdeba" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># List of binary fish species columns</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>fish_cols <span class="op">=</span> [</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Catfish'</span>, <span class="st">'Largemouth Bass'</span>, <span class="st">'Musky'</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Northern Pike'</span>, <span class="st">'Panfish'</span>, <span class="st">'Smallmouth Bass'</span>,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Sturgeon'</span>, <span class="st">'Trout'</span>, <span class="st">'Walleye'</span>]</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Establish an empty results dictionary</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>chi2_stats <span class="op">=</span> {}</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through fish columns and compute Chi-square stat vs. hasservice</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> fish_cols:</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    contingency_table <span class="op">=</span> pd.crosstab(df[col], df[<span class="st">'hasservice'</span>])</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    chi2_stat, p_value, dof, expected <span class="op">=</span> chi2_contingency(contingency_table)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    chi2_stats[col] <span class="op">=</span> [chi2_stat, p_value, dof, expected]</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Initilize the beginning of a discussion</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>chi2_summary <span class="op">=</span> <span class="st">"All fish species columns appear to offer some predictive value. "</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate and populate discussion with results from the analysis</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (species, stats) <span class="kw">in</span> <span class="bu">list</span>(<span class="bu">enumerate</span>(chi2_stats.items()))[:<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(f"{species}: χ² = {stats[0]:.3f} (p-value = {stats[1]:.4f)")</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    chi2_summary <span class="op">+=</span> <span class="ss">f"""For </span><span class="sc">{</span>species<span class="sc">.</span>lower()<span class="sc">}</span><span class="ss"> we find the χ² value of </span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="ss">        </span><span class="sc">{</span>stats[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss"> (p-value = </span><span class="sc">{</span>stats[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">). """</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Write the last entry of the iterative discussion</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>chi2_summary <span class="op">+=</span> <span class="ss">f"""And finally for </span><span class="sc">{</span>species<span class="sc">}</span><span class="ss"> we </span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="ss">        find the we find the χ² value of </span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="ss">        </span><span class="sc">{</span>stats[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss"> (p-value = </span><span class="sc">{</span>stats[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">)."""</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the discussion</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>display(Markdown(chi2_summary))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display cell-output-markdown">
<p>All fish species columns appear to offer some predictive value. For catfish we find the χ² value of 70.197 (p-value = 0.0000). For largemouth bass we find the χ² value of 1370.317 (p-value = 0.0000). For musky we find the χ² value of 579.412 (p-value = 0.0000). For northern pike we find the χ² value of 1269.510 (p-value = 0.0000). For panfish we find the χ² value of 1314.865 (p-value = 0.0000). For smallmouth bass we find the χ² value of 504.343 (p-value = 0.0000). For sturgeon we find the χ² value of 67.221 (p-value = 0.0000). For trout we find the χ² value of 197.378 (p-value = 0.0000). And finally for Trout we find the we find the χ² value of 197.378 (p-value = 0.0000).</p>
</div>
</div>
</section>
<section id="machine-learning-predictions-as-recommendations" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="machine-learning-predictions-as-recommendations"><span class="header-section-number">3.6</span> Machine Learning Predictions As Recommendations</h2>
<p><span class="citation" data-cites="james2023introduction">James et al. (<a href="#ref-james2023introduction" role="doc-biblioref">2023</a>)</span> explain that “broadly speaking, supervised statistical learning involves building a statistical model for predicting, or estimating, an output based on one or more inputs” (p.&nbsp;1). Data science methods genreally aim to leverage a series of features which can reliably predict an outcome.</p>
<p>In this paper’s analysis the outcome is whether a lake has as public service while the predictors are each lake’s size in acers, maximum depth, mean depth, latitude, longitude, type (missing, drainage, seepage, spring, drained), clarity (missing, low, moderate, very clear, very low), and the presence of specific fish species (catfish, largemouth bass, musky, northern pike, panfish, smallmouth bass, sturgeon, trout, walleye).</p>
<p>Through the use of a predictive algorithm that measures similarity this paper’s analysis will first create a model that looks to predict which of Wisconsin’s lakes have a public service and which of Wisconsin’s lakes do not have a public service. Inevitably there will be some errors.</p>
<p>One set of errors will be lakes that do not have a service but that the model predicted would (becauase they are similar to others that do) which we will call overserviced. Likewise another set of errors will be lakes that do have a service but that model predicted would not (becuase these other lakes are more similar to those that do not have service) which we will call underserviced.</p>
</section>
<section id="k-nearest-neighbors-knn" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="k-nearest-neighbors-knn"><span class="header-section-number">3.7</span> k-Nearest Neighbors (KNN)</h2>
<p>To classify whether a lake should or should not have a public service, this paper turns to a classic algorithm known as k-Nearest Neighbors (KNN). More traditionally, this algorithm serves to predict class membership based on an observation’s similarity to other observations of a known classification.</p>
<p>KNN is a non-parametric, instance-based learning algorithm that does not make assumptions about the underlying distribution of the data. Instead, it classifies instances based on the majority class of their closest neighbors in a feature space. Which is a technical manner of explaining that KNN is a way for a computer algorithm to make predictions or conclusions about an object based on what it “sees” (or measures using euclidian distances) as other similar objects.</p>
<p>A simplified version of the KNN process, as it operates for this paper, is to first observe an unknown lake and its characteristic features. Suppose the unknown lake is less than one acre in surface area and also less than 6 feet deep at its max. Then further suppose that 99% of all lakes less than an acre in size and also around 6 feet deep (+/- one foot) have no public service. Thus it would appear that the unknown lake is similar to lakes with no service and accordingly the algorithm would predict the uknown lake as one that also would have no public services.</p>
<p>In data science we use the term <em>non-parametric</em> to describe predictive algorithms, such as KNN, which have no fixed formula. Being absent a fixed formula distinguishes the non-parametic approach from parametric approaches, such as logistic regression, for example. <span class="citation" data-cites="james2023introduction">James et al. (<a href="#ref-james2023introduction" role="doc-biblioref">2023</a>)</span> describe KNN as one of “the simplest and best-known non-parametric methods” (p.&nbsp;111).</p>
<p>Models that are <em>instance-based</em> make decisions by comparing one instance (or given this paper’s data any instance of a given lake) to others instances (other lakes). During the model fit procedure the algorithm memorizes the training data by storing as a reference all training instances. A <em>feature space</em> is a term for the way we describe the multi-dimensional, or multi-variate, nature of the predictive features and their values.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This distance metric must not be conflated for geographic distance. For example, two lakes located on opposite sides of the state may still be considered “close” in feature space if they share similar size, depth, water clarity, and fish populations. This abstract notion of distance allows KNN to make predictions based on overall similarity in characteristics, rather than geographic location alone.</p>
</div>
</div>
<p>In this paper’s data, the feature space includes dimensions such as lake size, maximum depth, mean depth, latitude, longitude, water clarity, and the presence of specific fish species. The KNN algorithm uses this feature space to calculate distances between lakes and identify their nearest neighbors, which helps classify them based on their similarity.</p>
</section>
</section>
<section id="analysis" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Analysis</h1>
<p>This analysis uses the open-source Python package Scikit-learn (https://scikit-learn.org), a widely adopted and well-documented framework for implementing machine learning models, including k-nearest neighbors (KNN). Scikit-learn supports reproducible and transparent research, making it ideal for applications in data science and policy evaluation.</p>
<p><strong>TODO: Add Sklearn documenation as a source.</strong></p>
<p>The analytical procedures in this paper align with those outlined in Chapter 11 of <span class="citation" data-cites="nelson2023confident">Nelson (<a href="#ref-nelson2023confident" role="doc-biblioref">2023</a>)</span> and Chapter 3 of <span class="citation" data-cites="raschka2019python">Raschka and Mirjalili (<a href="#ref-raschka2019python" role="doc-biblioref">2019</a>)</span>. Most machine learning workflows begin by splitting the available data into training and testing sets. The training set allows the model to learn patterns and relationships in the data, while the testing set remains untouched until final evaluation. This split helps ensure that performance estimates reflect how the model will generalize to new data not seen during training.</p>
<p>The training and testing sets also support model parameter selection. In this case the parameter to optimize is the optimal number of <em>k</em> neighbors in the KNN algorithm. As is also customary, to avoid information leakage, this analysis performs data preprocessing after the data has been split. Binary features (such as fish species presence) require no further transformation. However, nominal features such as clarity and type are converted into dummy variables using one-hot encoding, and all continuous predictors are rescaled using a standardization procedure to ensure they contribute equally to distance calculations.</p>
<p>Following transformation, the next step involves conducting a parameter search to identify the most effective value for <em>k</em>, the number of nearest neighbors used in the KNN algorithm. In most cases, the customary approach is to select the smallest value of <em>k</em> that also minimizes prediction error. A smaller <em>k</em> yields a simpler, more interpretable model. However, this paper intentionally selects a less-well performing k value to relize a more complex model. The reasoning behind this choice is practical: a more complex model yields a finer-grained and more complete distribution of predicted probabilities. These probabilities in turn, support a more nuanced analysis of false predictions. As the anslysis seeks to identify lakes that do not have public services but appear similar to those that do, and vice versa. This added granularity enhances the utility of the model in producing actionable policy recommendations.</p>
<p>As a final step, this analysis uses a two-fold cross-validation with symmetric evaluation, which ensures that every lake is evaluated as an out-of-sample observation exactly once. In the first fold, the model is trained on half of the data and used to predict outcomes for the other half; in the second fold, the roles are reversed. This method yields a complete set of out-of-sample predictions, which allows us to identify false positives (lakes without public services that resemble lakes that do) and false negatives (lakes with public services that resemble those that don’t). These classification errors serve as the empirical foundation for the policy recommendations presented later in this paper.</p>
<section id="train-test-split-procedure" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="train-test-split-procedure"><span class="header-section-number">4.1</span> Train Test Split Procedure</h2>
<p>The SciKit Learn user guide states plainly that “Learning the parameters of a prediction function and testing it on the same data is a methodological mistake” <span class="citation" data-cites="scikit-learn-cross-validation2023">Scikit-Learn (<a href="#ref-scikit-learn-cross-validation2023" role="doc-biblioref">2023</a>)</span>. This mistake would usually lead to a model that has <em>overfit</em>. Instead of finding the general functional relationships between predictor features and an outcome, a model that has overfit to the data, has come close to memorizing the training data.</p>
<p>By first fitting a model on a subset of training data and then using a separate hold out subset as a test, the procedure results in a more objective opportunity to fairly evaluate the predictive abilities of a model. The procedure ensures that a model which performs well on training data also later performs well on new data yet to be generated in future production settings.</p>
<div id="bc3de0b3-dc41-4f33-a6c6-f90da1b99bad" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Organize Features + Predictors</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>ready_features <span class="op">=</span> [</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Catfish'</span>,<span class="st">'Largemouth Bass'</span>, <span class="st">'Musky'</span>, <span class="st">'Northern Pike'</span>, </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Panfish'</span>, <span class="st">'Smallmouth Bass'</span>, <span class="st">'Sturgeon'</span>, <span class="st">'Trout'</span>, <span class="st">'Walleye'</span>]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>con_features <span class="op">=</span> [<span class="st">'size'</span>,<span class="st">'maxdepth'</span>, <span class="st">'meandepth'</span>, <span class="st">'lat'</span>, <span class="st">'lon'</span>]</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>bin_features <span class="op">=</span> [<span class="st">'maxdepth_missing'</span>, <span class="st">'meandepth_missing'</span>]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>cat_features <span class="op">=</span> [<span class="st">'type'</span>, <span class="st">'clarity'</span>]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Establish X (predictor) and y (target) matricies</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[con_features <span class="op">+</span> bin_features <span class="op">+</span> ready_features <span class="op">+</span> cat_features]</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'hasservice'</span>]</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform train test split with SkLearn</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.30</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="rescale-continuous-data" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="rescale-continuous-data"><span class="header-section-number">4.2</span> Rescale Continuous Data</h2>
<p>According to <span class="citation" data-cites="raschka2019python">Raschka and Mirjalili (<a href="#ref-raschka2019python" role="doc-biblioref">2019</a>)</span> “the majority of machine learning… algorithms behave much better if features are on the same scale” (p.&nbsp;124). In the case of KNN, an algorithm that relies on calculating distances between data points in the feature space, if the features spread across vastly different scales, those with larger ranges will dominate the distance calculations.</p>
<p>Fitting a KNN on features that are differently scaled may potentially lead to biased classifications. For instance, if one feature represents lake size in acres (ranging from tens to thousands) and another represents water clarity on a scale of 1 to 100, the size feature will disproportionately influence the nearest neighbor determination. Thus, For KNN, rescaling ensures that all features contribute equally to the distance metric <span class="citation" data-cites="nelson2023confident">(<a href="#ref-nelson2023confident" role="doc-biblioref">Nelson 2023, 317</a>)</span>.</p>
<p>To address this issue, continuous data is typically rescaled to 0 to 1, -1 to 1, or to z-score values which places the mean at 0 and then shifts values so there is a standard deviation of 1. In this paper I proceed with a 0 to 1 scale.</p>
<div id="3a03c903-99b8-4e5b-bdae-28487e5c5b5b" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>ohe <span class="op">=</span> OneHotEncoder(sparse_output<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                    handle_unknown<span class="op">=</span><span class="st">'ignore'</span>).set_output(transform<span class="op">=</span><span class="st">'pandas'</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Rescale continuous variables</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>X_train[con_features] <span class="op">=</span> scaler.fit_transform(X_train[con_features])</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>X_test[con_features] <span class="op">=</span> scaler.transform(X_test[con_features])</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># One hot encode nominal categorical</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>X_train_ohe <span class="op">=</span> ohe.fit_transform(X_train[cat_features])</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>X_test_ohe <span class="op">=</span> ohe.transform(X_test[cat_features])</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop original categorical cols and concat OHE output</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> pd.concat([X_train.drop(cat_features, axis<span class="op">=</span><span class="dv">1</span>), X_train_ohe], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> pd.concat([X_test.drop(cat_features, axis<span class="op">=</span><span class="dv">1</span>), X_test_ohe], axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="fit-base-model" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="fit-base-model"><span class="header-section-number">4.3</span> Fit Base Model</h2>
<p>Before proceeding with parameter tuning or model refinement, it is often useful to fit a base model using an arbitrary but reasonable choice of parameters. In the case of k-nearest neighbors (KNN), selecting a base <em>k</em> such as <em>k</em> = 19. This base model provides an initial benchmark for model performance. This step, though technically optional, serves several important purposes within the broader analytical process.</p>
<p>First, fitting a base model allows the analyst to ensure that the pipeline—from data preprocessing to model training and evaluation functioned as intended. Errors related to data structure, scaling, encoding, or other preprocessing steps often surface during this preliminary fit. The base model thus acts as a diagnostic opportunity to detect problems before introducing additional complexity through cross-validation, parameter searches, or other hyperparameter tuning efforts.</p>
<p>Second, the base model offers a reference point for evaluating the value added by subsequent modeling decisions. For example, if the accuracy or error rate of a tuned model differs only marginally from that of the base model, the analyst may reconsider the complexity or interpretability trade-offs involved in optimization. Conversely, large improvements over the base model suggest meaningful gains that justify further refinement.</p>
<p>Finally, the base model supports replication and transparency by providing a fixed and reproducible result that others can use to validate or extend the work. By producing and recording model performance with arbitrary but documented parameters, the analysis builds a foundation upon which subsequent results can be compared, especially in applied contexts where interpretability and policy implications matter as much as technical performance.</p>
<p>In short, while fitting a base model with arbitrary <em>k</em> is not strictly necessary for most analyses, it offers extensive practical value in building a rigorous, transparent, and well-structured analysis.</p>
<div id="24e72393-3e31-4bcd-8277-47167aa389d9" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate a base model with 19 neighbors</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>knn_base <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">19</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using training data</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>knn_base.fit(X_train, y_train)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn_base.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>This base model yeild 0.7605268409499102 accuracy (correct classifications). There were 403 false positive predictions and 797 false negative predictions. These base metrics can serve as a helpful reference when evaluating futher results below.</p>
</section>
<section id="evaluate-search-for-optimal-k" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="evaluate-search-for-optimal-k"><span class="header-section-number">4.4</span> Evaluate + Search for Optimal K</h2>
<p>This portion of the analysis implements a parameter search to determine how the choice of <em>k</em> (the number of neighbors considered in the KNN classification algorithm) affects model performance. The goal is to identify a value of <em>k</em> that yields relatively low classification error, thereby improving the model’s predictive accuracy. As discussed above, for this paper I will not choose the lowest error rate in order to support a fully nuanced analysis.</p>
<p>This portion of the analysis begins by initializing an empty list named <code>error_rates</code> to store the error rate associated with each value of <em>k</em>. The <code>for</code> loop then iterates through odd-numbered values of <em>k</em> from 1 to 99. Odd values avoid tie votes in binary classification. For each iteration, the code instantiates a new <code>KNeighborsClassifier</code> model using the current value of <em>k</em> and fits it to the training data.</p>
<p>Once trained the code predicts classifications for the testing set (<code>X_test</code>), then calculates the error rate as the proportion of incorrect predictions, and appends that result to the <code>error_rates</code> list. By the end of the loop, the list holds the model’s error rates across a range of <em>k</em> values.</p>
<div id="93d82fcd-f230-4d50-ad96-d7a61c9a34b0" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate an empty list of errors</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>error_rates <span class="op">=</span> []</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through odd numbered neighbors 1 through 99</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">2</span>):</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The KNN classification model</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    knn.fit(X_train, y_train)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate predictions on the testing data</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    y_pred_kn <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate and record proprtion of correct classifications</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    error_rates.append(np.mean(y_pred_kn <span class="op">!=</span> y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A subsequent block of code generates <a href="#fig-error_rates" class="quarto-xref">Figure&nbsp;6</a>, a visual representation of the results using Matplotlib. <a href="#fig-error_rates" class="quarto-xref">Figure&nbsp;6</a> uses a dotted blue line with ‘x’ markers to show how error rates change as <em>k</em> increases.</p>
<p>By examining <a href="#fig-error_rates" class="quarto-xref">Figure&nbsp;6</a>’s curve, an analyst can make an informed decision about which <em>k</em> values to consider for the final model—balancing error rate, model simplicity, and practical interpretability. Given these results I choose a <em>k</em> value of 29 consistent with the procedure outlined above.</p>
<div class="cell" data-fig-num="true" data-execution_count="25">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the results of the search above</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))           <span class="co"># Landscape Sizing</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Match plot range to for loop above - add style for readability</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">2</span>), error_rates, color<span class="op">=</span><span class="st">'blue'</span>,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>         linestyle<span class="op">=</span><span class="st">':'</span>, marker<span class="op">=</span><span class="st">'x'</span>, markersize<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>plt.annotate(text<span class="op">=</span><span class="st">'Chosen K (29)'</span>, </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>             xy<span class="op">=</span>(<span class="dv">30</span>, <span class="fl">.233</span>), xytext<span class="op">=</span>(<span class="dv">50</span>, <span class="fl">.237</span>), fontsize<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>             arrowprops<span class="op">=</span>{<span class="st">'arrowstyle'</span>:<span class="st">'-&gt;'</span>, <span class="st">'connectionstyle'</span>:<span class="st">'arc3, rad=-.2'</span>})</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Error vs. K Values'</span>)      <span class="co"># Chart Title</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'K Value'</span>)                <span class="co"># X Axis Title</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Error Rate'</span>)             <span class="co"># Y Axis Title</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-error_rates" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-fig-num="true" data-execution_count="25">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-error_rates-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="fig-error_rates-1" class="cell-output cell-output-display quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="25">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-error_rates-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<pre id="fig-error_rates-1" class="cell-output cell-output-display" data-execution_count="25"><code>Text(0, 0.5, 'Error Rate')</code></pre>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-error_rates-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) A plot showing error rate over a range of k values.
</figcaption>
</figure>
</div>
<div class="cell-output cell-output-display">
<div id="fig-error_rates-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-error_rates-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ParkSiteSelection_files/figure-html/fig-error_rates-output-2.png" id="fig-error_rates-2" class="img-fluid figure-img" data-ref-parent="fig-error_rates">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-error_rates-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-error_rates-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6
</figcaption>
</figure>
</div>
</div>
</section>
<section id="two-fold-cross-validation-symmetric-evaluation" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="two-fold-cross-validation-symmetric-evaluation"><span class="header-section-number">4.5</span> Two-fold cross-validation; Symmetric evaluation</h2>
<p>In executing this procedure I first split the data into two equal halves. In the first fold, I train the model on the first half and predict on the second; in the second fold, the I reverse the process.</p>
<p>As before, within each fold, continuous variables are standardized using <code>StandardScaler</code> and nominal categorical variables are transformed via one-hot encoding using <code>OneHotEncoder</code>.</p>
<p>After each fit, train, and predict I record both the prediction and also the probability of membership in the <code>hasservice</code> class. Finally, I combine predictions from both folds and merged them back into the original data. The result is a full set of out-of-sample predictions and prediction probabilities for each observation.</p>
<div id="1a5b49c4-6de1-4e04-9ec5-f84644520445" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Establish X (predictor) and y (target) matricies</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[con_features <span class="op">+</span> bin_features <span class="op">+</span> ready_features <span class="op">+</span> cat_features]</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'hasservice'</span>]</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># # Perform initial 50/50 split</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>X_A, X_B, y_A, y_B <span class="op">=</span> train_test_split(</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> execute_fold(X_train, X_test, y_train, y_test):</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    ohe <span class="op">=</span> OneHotEncoder(sparse_output<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>                        handle_unknown<span class="op">=</span><span class="st">'ignore'</span>).set_output(transform<span class="op">=</span><span class="st">'pandas'</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Rescale continuous variables</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    X_train[con_features] <span class="op">=</span> scaler.fit_transform(X_train[con_features])</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    X_test[con_features] <span class="op">=</span> scaler.transform(X_test[con_features])</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># One hot encode nominal categorical</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    X_train_ohe <span class="op">=</span> ohe.fit_transform(X_train[cat_features])</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    X_test_ohe <span class="op">=</span> ohe.transform(X_test[cat_features])</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Drop original categorical cols and concat OHE output</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    X_train <span class="op">=</span> pd.concat([X_train.drop(cat_features, axis<span class="op">=</span><span class="dv">1</span>), X_train_ohe], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    X_test <span class="op">=</span> pd.concat([X_test.drop(cat_features, axis<span class="op">=</span><span class="dv">1</span>), X_test_ohe], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Instantiate KNN Model</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    knn_cross <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">29</span>)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the model using training data</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    knn_cross.fit(X_train, y_train)</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame({</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">'predicted'</span>: knn_cross.predict(X_test),</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">'probability'</span>: knn_cross.predict_proba(X_test)[: ,<span class="dv">1</span>]},</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        index<span class="op">=</span>X_test.index)</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Train on A, predict on B</span></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>y_B_pred <span class="op">=</span> execute_fold(X_A, X_B, y_A, y_B)</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Train on B, predict on A</span></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>y_A_pred <span class="op">=</span> execute_fold(X_B, X_A, y_B, y_A)</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Stack the predictions</span></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>y_preds <span class="op">=</span> pd.concat([y_B_pred, y_A_pred])</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Recompile the full data set</span></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>output_cols <span class="op">=</span> [<span class="st">'ID'</span>, <span class="st">'name'</span>, <span class="st">'size'</span>, <span class="st">'maxdepth'</span>, <span class="st">'meandepth'</span>, </span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>       <span class="st">'lat'</span>, <span class="st">'lon'</span>, <span class="st">'hasservice'</span>, <span class="st">'haslanding'</span>, <span class="st">'hasbeach'</span>, </span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>       <span class="st">'haspark'</span>, <span class="st">'type'</span>, <span class="st">'clarity'</span>, <span class="st">'county'</span>]</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>output_data <span class="op">=</span> df[output_cols].copy()</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>output_data <span class="op">=</span> output_data.merge(</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>    y_preds, left_index<span class="op">=</span><span class="va">True</span>, right_index<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>    validate<span class="op">=</span><span class="st">'one_to_one'</span>)</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Save output_data to csv</span></span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>output_data.to_csv(<span class="st">'output_data.csv'</span>, index<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="results" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Results</h1>
<p>This analysis produced 4216 false predictions. A full list of all the lakes analyzed in this study and the predictive results accompanies this project in a file called <code>output_data.csv</code>.</p>
<div id="87eaa449-0491-48da-9302-4769750a8d2e" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarise results, count false predictions</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>false_preds_count <span class="op">=</span> <span class="bu">sum</span>(output_data[<span class="st">'hasservice'</span>] <span class="op">!=</span> output_data[<span class="st">'predicted'</span>])</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for false positives</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>false_positives <span class="op">=</span> output_data[</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    (output_data[<span class="st">'hasservice'</span>] <span class="op">==</span> <span class="dv">0</span>) <span class="op">&amp;</span> </span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    (output_data[<span class="st">'predicted'</span>] <span class="op">==</span> <span class="dv">1</span>)]</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Save count of false positives</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>false_positive_count <span class="op">=</span> false_positives.shape[<span class="dv">0</span>]</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for false negatives</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>false_negatives <span class="op">=</span> output_data[</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    (output_data[<span class="st">'hasservice'</span>] <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> </span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    (output_data[<span class="st">'predicted'</span>] <span class="op">==</span> <span class="dv">0</span>)]</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Save count of false negatives</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>false_negative_count <span class="op">=</span> false_negatives.shape[<span class="dv">0</span>]</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Save these data for later reference</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">"_variables.yml"</span>, <span class="st">"a"</span>) <span class="im">as</span> f:</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f"false_preds_count: </span><span class="sc">{</span>false_preds_count<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f"false_positive_count: </span><span class="sc">{</span>false_positive_count<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="ss">f"false_negative_count: </span><span class="sc">{</span>false_negative_count<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="8630309a-ce3f-4a80-8b8f-ac1b578ad57a" class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initiate paragraph describing false positive results</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>false_pos_desc <span class="op">=</span> <span class="ss">f"Overall there were </span><span class="sc">{</span>false_positive_count<span class="sc">}</span><span class="ss"> false positives. "</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>false_pos_desc <span class="op">+=</span> <span class="st">"Among the false positives there were "</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Write paragraph describing false positive results</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> p, lcount <span class="kw">in</span> <span class="bu">list</span>(</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    false_positives[<span class="st">'probability'</span>].value_counts().sort_index().to_dict().items())[:<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    false_pos_desc <span class="op">+=</span> <span class="ss">f"</span><span class="sc">{</span>lcount<span class="sc">}</span><span class="ss"> lakes with a </span><span class="sc">{</span>p<span class="sc">:.2f}</span><span class="ss"> probability of having service, "</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Add last clause with special handeling</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>p, lcount <span class="op">=</span> <span class="bu">list</span>(</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    false_positives[<span class="st">'probability'</span>].value_counts().sort_index().to_dict().items())[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>false_pos_desc <span class="op">+=</span> <span class="ss">f"and in the last probability level there were </span><span class="sc">{</span>lcount<span class="sc">}</span><span class="ss"> lakes "</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>false_pos_desc <span class="op">+=</span> <span class="ss">f"with a </span><span class="sc">{</span>p<span class="sc">:.2f}</span><span class="ss"> probability of having service."</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Initiate paragraph describing false negative results</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>false_neg_desc <span class="op">=</span> <span class="ss">f"This analysis yielded </span><span class="sc">{</span>false_negative_count<span class="sc">}</span><span class="ss"> false negatives. "</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>false_neg_desc <span class="op">+=</span> <span class="st">"Among the false negatives there were "</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Write paragraph describing false negative results</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> p, lcount <span class="kw">in</span> <span class="bu">list</span>(</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    false_negatives[<span class="st">'probability'</span>].value_counts().sort_index().to_dict().items())[:<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    false_neg_desc <span class="op">+=</span> <span class="ss">f"</span><span class="sc">{</span>lcount<span class="sc">}</span><span class="ss"> lakes with a </span><span class="sc">{</span>p<span class="sc">:.2f}</span><span class="ss"> probability of having service, "</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Add last clause with special handeling</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>p, lcount <span class="op">=</span> <span class="bu">list</span>(</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    false_negatives[<span class="st">'probability'</span>].value_counts().sort_index().to_dict().items())[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>false_neg_desc <span class="op">+=</span> <span class="ss">f"and lastly there were </span><span class="sc">{</span>lcount<span class="sc">}</span><span class="ss"> lakes "</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>false_neg_desc <span class="op">+=</span> <span class="ss">f"with a </span><span class="sc">{</span>p<span class="sc">:.2f}</span><span class="ss"> probability of having service."</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Display paragraph regarding false positives</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>display(Markdown(false_pos_desc))</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Display paragraph regarding false negatives</span></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>display(Markdown(false_neg_desc))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Overall there were 1237 false positives. Among the false positives there were 297 lakes with a 0.52 probability of having service, 254 lakes with a 0.55 probability of having service, 200 lakes with a 0.59 probability of having service, 128 lakes with a 0.62 probability of having service, 117 lakes with a 0.66 probability of having service, 96 lakes with a 0.69 probability of having service, 51 lakes with a 0.72 probability of having service, 44 lakes with a 0.76 probability of having service, 22 lakes with a 0.79 probability of having service, 14 lakes with a 0.83 probability of having service, 4 lakes with a 0.86 probability of having service, 2 lakes with a 0.90 probability of having service, 4 lakes with a 0.93 probability of having service, 2 lakes with a 0.97 probability of having service, and in the last probability level there were 2 lakes with a 1.00 probability of having service.</p>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>This analysis yielded 2979 false negatives. Among the false negatives there were 21 lakes with a 0.00 probability of having service, 82 lakes with a 0.03 probability of having service, 121 lakes with a 0.07 probability of having service, 121 lakes with a 0.10 probability of having service, 144 lakes with a 0.14 probability of having service, 187 lakes with a 0.17 probability of having service, 175 lakes with a 0.21 probability of having service, 177 lakes with a 0.24 probability of having service, 179 lakes with a 0.28 probability of having service, 229 lakes with a 0.31 probability of having service, 275 lakes with a 0.34 probability of having service, 325 lakes with a 0.38 probability of having service, 292 lakes with a 0.41 probability of having service, 334 lakes with a 0.45 probability of having service, and lastly there were 317 lakes with a 0.48 probability of having service.</p>
</div>
</div>
<section id="underserved-lakes" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="underserved-lakes"><span class="header-section-number">5.1</span> Underserved Lakes</h2>
<p>Underserved lakes are the lakes that this analysis falsely predicted not to have services, but that actually do have services. Because the results produced 1237 false positives I further refine the definition of underserved lakes to include those that had a probability of service greater than .80. <a href="#tbl-overserviced-lakes" class="quarto-xref">Table&nbsp;4</a> provides a full list of underserviced lakes.</p>
<div style="font-size: 12px;">
<div class="cell" data-tbl-num="true" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>false_positives[false_positives[<span class="st">'probability'</span>] <span class="op">&gt;</span> <span class="fl">.8</span>][</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'name'</span>,<span class="st">'size'</span>,<span class="st">'lat'</span>,<span class="st">'lon'</span>,<span class="st">'county'</span>,<span class="st">'probability'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="tbl-underserviced-lakes" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-tbl-num="true" data-execution_count="30">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-underserviced-lakes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: A list of underservied lakes (false positives).
</figcaption>
<div aria-describedby="tbl-underserviced-lakes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="30">
<div>


<table class="dataframe do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">name</th>
<th data-quarto-table-cell-role="th">size</th>
<th data-quarto-table-cell-role="th">lat</th>
<th data-quarto-table-cell-role="th">lon</th>
<th data-quarto-table-cell-role="th">county</th>
<th data-quarto-table-cell-role="th">probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">153</td>
<td>Balmoral Pond</td>
<td>59.00</td>
<td>43.226486</td>
<td>-90.470669</td>
<td>Richland</td>
<td>0.862069</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">814</td>
<td>Callahan Lake</td>
<td>138.00</td>
<td>45.989217</td>
<td>-91.239951</td>
<td>Sawyer</td>
<td>0.862069</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1682</td>
<td>Fence Lake</td>
<td>3483.00</td>
<td>45.950856</td>
<td>-89.839401</td>
<td>Vilas</td>
<td>0.965517</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2635</td>
<td>Kettle Moraine Lake</td>
<td>209.00</td>
<td>43.653256</td>
<td>-88.210314</td>
<td>Fond du Lac</td>
<td>0.931034</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2645</td>
<td>Kilbourn Flowage</td>
<td>1868.00</td>
<td>43.671867</td>
<td>-89.800722</td>
<td>Juneau, Adams</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2887</td>
<td>Lake Placid</td>
<td>178.00</td>
<td>46.026224</td>
<td>-91.281368</td>
<td>Sawyer</td>
<td>0.862069</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3002</td>
<td>Lee Lake</td>
<td>30.00</td>
<td>44.187680</td>
<td>-90.647376</td>
<td>Jackson</td>
<td>0.827586</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3298</td>
<td>Little Yellow Lake</td>
<td>332.00</td>
<td>45.929222</td>
<td>-92.430777</td>
<td>Burnett</td>
<td>0.931034</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3679</td>
<td>McClaine Lake</td>
<td>53.00</td>
<td>46.061263</td>
<td>-91.296472</td>
<td>Sawyer</td>
<td>0.827586</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3899</td>
<td>Moon Lake</td>
<td>131.00</td>
<td>45.917882</td>
<td>-89.434357</td>
<td>Vilas</td>
<td>0.827586</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3926</td>
<td>Moshawquit Lake</td>
<td>301.00</td>
<td>44.897214</td>
<td>-88.500481</td>
<td>Menominee</td>
<td>0.931034</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4231</td>
<td>North Lake</td>
<td>440.00</td>
<td>43.150269</td>
<td>-88.382004</td>
<td>Waukesha</td>
<td>0.827586</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4244</td>
<td>North Spirit Lake</td>
<td>224.00</td>
<td>45.384151</td>
<td>-90.152486</td>
<td>Price, Taylor</td>
<td>0.827586</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4292</td>
<td>Oconomowoc Lake</td>
<td>818.00</td>
<td>43.098846</td>
<td>-88.453462</td>
<td>Waukesha</td>
<td>0.827586</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4591</td>
<td>Pine Lake</td>
<td>217.00</td>
<td>44.686275</td>
<td>-88.658210</td>
<td>Shawano</td>
<td>0.896552</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4629</td>
<td>Pioneer Lake</td>
<td>429.00</td>
<td>46.016883</td>
<td>-89.206059</td>
<td>Vilas</td>
<td>0.931034</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4642</td>
<td>Planting Ground Lake</td>
<td>1010.00</td>
<td>45.835412</td>
<td>-89.157076</td>
<td>Oneida</td>
<td>0.965517</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5486</td>
<td>Spring Lake</td>
<td>207.00</td>
<td>46.175883</td>
<td>-89.356167</td>
<td>Vilas</td>
<td>0.827586</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5593</td>
<td>Stone Lake</td>
<td>249.00</td>
<td>45.830118</td>
<td>-89.973107</td>
<td>Oneida</td>
<td>0.827586</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">8310</td>
<td>Unnamed</td>
<td>9.00</td>
<td>46.171960</td>
<td>-91.222243</td>
<td>Bayfield</td>
<td>0.827586</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9096</td>
<td>Unnamed</td>
<td>2.00</td>
<td>46.263889</td>
<td>-91.280064</td>
<td>Bayfield</td>
<td>0.827586</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11738</td>
<td>Unnamed</td>
<td>0.12</td>
<td>46.237242</td>
<td>-91.300065</td>
<td>Bayfield</td>
<td>0.827586</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12333</td>
<td>Unnamed</td>
<td>1.00</td>
<td>45.962767</td>
<td>-88.728253</td>
<td>Forest</td>
<td>0.896552</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">14807</td>
<td>Unnamed</td>
<td>1.00</td>
<td>45.891822</td>
<td>-89.464119</td>
<td>Oneida</td>
<td>0.827586</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">15028</td>
<td>Unnamed</td>
<td>4.00</td>
<td>45.239176</td>
<td>-91.405471</td>
<td>Chippewa</td>
<td>0.862069</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">16314</td>
<td>Upper Kaubashine Lake</td>
<td>181.00</td>
<td>45.789425</td>
<td>-89.740638</td>
<td>Oneida</td>
<td>0.827586</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16439</td>
<td>Waubeesee Lake</td>
<td>139.00</td>
<td>42.816975</td>
<td>-88.168255</td>
<td>Racine</td>
<td>0.827586</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">16451</td>
<td>Webb Lake</td>
<td>756.00</td>
<td>46.030756</td>
<td>-92.134974</td>
<td>Burnett</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
</div>
<p><a href="#tbl-underserviced-lakes" class="quarto-xref">Table&nbsp;3</a> presents a list of lakes identified by KNN model as false positives, or as lakes that were predicted to have public services but do not currently offer them. Each row includes the lake’s name, its surface area in acres (<code>size</code>), geographic coordinates (<code>lat</code> and <code>lon</code>), the county or counties in which the lake is located, and the model’s estimated <code>probability</code>.</p>
<p>This <code>probability</code> value is a key element in the table: it represents the proportion of the 29 nearest neighbors (as set by the optimal <em>k</em> in the model) that do have a public service. For example, a probability of <code>0.827586</code> implies that 25 out of 29 neighboring lakes in the feature space had a public service, making the model highly confident that the lake in question should as well.</p>
<p>Lakes such as Kilbourn Flowage, Kettle Moraine Lake, and Fence Lake have especially high probabilities—approaching or reaching 1.0—indicating that all of their most similar lakes in the multi-dimensional feature space do have services. These high-probability false positives are particularly important because they suggest a strong pattern of similarity when compared to serviced lakes and thus may warrant prioritization for future investments in public amenities.</p>
</section>
<section id="overserviced-lakes" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="overserviced-lakes"><span class="header-section-number">5.2</span> Overserviced Lakes</h2>
<p>The opposite of underserved lakes, overserviced lakes are those that the model suggested would not have services but do (the false negatives). With 2979 false negatives it is also convenient to refine this definition. To reduce the number of lakes for consideration as overserviced I further refine the definition of overserviced lakes to only include those that had a probability of service less than .03. <a href="#tbl-underserviced-lakes" class="quarto-xref">Table&nbsp;3</a> provides a full list of these overserviced lakes.</p>
<div style="font-size: 12px;">
<div class="cell" data-tbl-num="true" data-execution_count="31">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>false_negatives[false_negatives[<span class="st">'probability'</span>] <span class="op">&lt;</span> <span class="fl">.03</span>][</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'name'</span>,<span class="st">'size'</span>,<span class="st">'lat'</span>,<span class="st">'lon'</span>,<span class="st">'county'</span>,<span class="st">'probability'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="tbl-overserviced-lakes" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-tbl-num="true" data-execution_count="31">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-overserviced-lakes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: A list of overserviced lakes (false positives).
</figcaption>
<div aria-describedby="tbl-overserviced-lakes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="31">
<div>


<table class="dataframe do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">name</th>
<th data-quarto-table-cell-role="th">size</th>
<th data-quarto-table-cell-role="th">lat</th>
<th data-quarto-table-cell-role="th">lon</th>
<th data-quarto-table-cell-role="th">county</th>
<th data-quarto-table-cell-role="th">probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">927</td>
<td>Ceylon Lagoon</td>
<td>6.00</td>
<td>42.569558</td>
<td>-88.436106</td>
<td>Walworth</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1797</td>
<td>Fountain City Bay</td>
<td>12.00</td>
<td>44.159725</td>
<td>-91.777910</td>
<td>Buffalo</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6511</td>
<td>Un Spring</td>
<td>2.00</td>
<td>44.590719</td>
<td>-89.275868</td>
<td>Portage</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">6726</td>
<td>Un Spring</td>
<td>0.43</td>
<td>45.393054</td>
<td>-89.142821</td>
<td>Langlade</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7085</td>
<td>Unnamed</td>
<td>0.16</td>
<td>45.353973</td>
<td>-87.835161</td>
<td>NaN</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">8064</td>
<td>Unnamed</td>
<td>15.00</td>
<td>45.423579</td>
<td>-87.846604</td>
<td>NaN</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8389</td>
<td>Unnamed</td>
<td>6.00</td>
<td>44.775488</td>
<td>-89.371965</td>
<td>Marathon</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">8390</td>
<td>Unnamed</td>
<td>11.00</td>
<td>44.775369</td>
<td>-89.363338</td>
<td>Marathon</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9414</td>
<td>Unnamed</td>
<td>6.00</td>
<td>45.590046</td>
<td>-92.411616</td>
<td>Polk</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9449</td>
<td>Unnamed</td>
<td>5.00</td>
<td>45.695333</td>
<td>-91.798330</td>
<td>Washburn</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9452</td>
<td>Unnamed</td>
<td>1.00</td>
<td>45.684841</td>
<td>-91.796190</td>
<td>Washburn</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10149</td>
<td>Unnamed</td>
<td>3.00</td>
<td>44.496448</td>
<td>-91.108335</td>
<td>Jackson</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10588</td>
<td>Unnamed</td>
<td>4.00</td>
<td>46.232631</td>
<td>-89.633780</td>
<td>Vilas</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10689</td>
<td>Unnamed</td>
<td>3.00</td>
<td>43.104593</td>
<td>-90.880959</td>
<td>Crawford</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">11213</td>
<td>Unnamed</td>
<td>1.00</td>
<td>45.337950</td>
<td>-89.198971</td>
<td>Langlade</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">12170</td>
<td>Unnamed</td>
<td>2.00</td>
<td>45.769352</td>
<td>-91.456846</td>
<td>Sawyer</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12402</td>
<td>Unnamed</td>
<td>0.13</td>
<td>46.464047</td>
<td>-90.185947</td>
<td>NaN</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">12951</td>
<td>Unnamed</td>
<td>4.00</td>
<td>45.467103</td>
<td>-89.314136</td>
<td>Langlade</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">13529</td>
<td>Unnamed</td>
<td>5.00</td>
<td>45.725096</td>
<td>-91.709003</td>
<td>Washburn</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">14248</td>
<td>Unnamed</td>
<td>3.00</td>
<td>43.106431</td>
<td>-90.879007</td>
<td>Crawford</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">15243</td>
<td>Unnamed</td>
<td>0.52</td>
<td>42.531563</td>
<td>-90.645786</td>
<td>NaN</td>
<td>0.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
</div>
<p><a href="#tbl-overserviced-lakes" class="quarto-xref">Table&nbsp;4</a> identifies lakes classified as false negatives by the KNN model. These lakes do have public services, but the model predicted they would not. In this analysis, such lakes are referred to as overserviced, meaning they are dissimilar—based on the features available—to most other lakes that also have services.</p>
<p>As was also with <a href="#tbl-underserviced-lakes" class="quarto-xref">Table&nbsp;3</a> this <code>probability</code> column reflects the proportion of the 29 most similar lakes (i.e., nearest neighbors in the multi-dimensional feature space) that had public services. A <code>probability</code> of 0.0 implies that none of the 29 neighbors had a service.</p>
<p>For example, Fountain City Bay and Ceylon Lagoon offer public services but are quite like at least 29 other unserviced lakes. Ultimately, <a href="#tbl-overserviced-lakes" class="quarto-xref">Table&nbsp;4</a> and <a href="#tbl-underserviced-lakes" class="quarto-xref">Table&nbsp;3</a> provide a data-driven starting point for reevaluating the current distribution of public services across Wisconsin’s lakes by identifying outliers that may represent opportunities for improved alignment with service needs. Whiel <a href="#fig-knn-false-predictions" class="quarto-xref">Figure&nbsp;7</a> shows the location of these underserviced and overserviced lakes.</p>
<div id="cell-fig-knn-false-predictions" class="cell" data-fig-num="true" data-execution_count="32">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Wisconsin outline</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>wisconsin <span class="op">=</span> fetch_wisconsin_geojson()</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter to subset of false predicitons</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>false_pos_strong <span class="op">=</span> false_positives[false_positives[<span class="st">'probability'</span>] <span class="op">&gt;</span> <span class="fl">.80</span>]</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>false_neg_strong <span class="op">=</span> false_negatives[false_negatives[<span class="st">'probability'</span>] <span class="op">&lt;</span> <span class="fl">.03</span>]</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Add error type labels</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>false_pos_strong[<span class="st">'Error Type'</span>] <span class="op">=</span> <span class="st">"False + Underserved"</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>false_neg_strong[<span class="st">'Error Type'</span>] <span class="op">=</span> <span class="st">"False - Overserviced"</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine for plotting</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>map_df <span class="op">=</span> pd.concat([false_pos_strong, false_neg_strong], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to GeoDataFrame</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>gdf_map <span class="op">=</span> gpd.GeoDataFrame(</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    map_df,</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    geometry<span class="op">=</span>gpd.points_from_xy(map_df[<span class="st">'lon'</span>], map_df[<span class="st">'lat'</span>]),</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    crs<span class="op">=</span><span class="st">"EPSG:4326"</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot state boundary</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>wisconsin.boundary.plot(ax<span class="op">=</span>ax, color<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">1.2</span>)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot predictions</span></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>gdf_map,</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">'lon'</span>, y<span class="op">=</span><span class="st">'lat'</span>,</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">'Error Type'</span>, style<span class="op">=</span><span class="st">'Error Type'</span>,</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>{<span class="st">'False + Underserved'</span>: <span class="st">'blue'</span>, <span class="st">'False - Overserviced'</span>: <span class="st">'black'</span>},</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    markers<span class="op">=</span>{<span class="st">'False + Underserved'</span>: <span class="st">'X'</span>, <span class="st">'False - Overserviced'</span>: <span class="st">'o'</span>},</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span><span class="dv">60</span>, ax<span class="op">=</span>ax, alpha<span class="op">=</span><span class="fl">0.8</span></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Set titles and labels</span></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"False Predictions from kNN Classification of Wisconsin Lakes"</span>)</span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Longitude"</span>)</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Latitude"</span>)</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>ax.legend(title<span class="op">=</span><span class="st">'Prediction Type'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-knn-false-predictions" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-knn-false-predictions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ParkSiteSelection_files/figure-html/fig-knn-false-predictions-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-knn-false-predictions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: False positive and false negative predictions from the kNN model mapped onto the state of Wisconsin.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The map in <a href="#fig-knn-false-predictions" class="quarto-xref">Figure&nbsp;7</a> presents a visualization of false predictions generated by the KNN classification model trained to identify which Wisconsin lakes have public services—such as boat landings, beaches, or parks—based. Specifically, it highlights two important categories of interest for policy consideration: underserved lakes and overserviced lakes.</p>
</section>
</section>
<section id="further-discussion" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Further Discussion</h1>
<p>Lakes marked with blue “x” symbols represent false positives, or underserved lakes. These underserved lakes are those that the model predicted to have public services, because they are similar to other lakes that do, but that in reality do not have public services. These lakes may warrant further investigation as candidates for the addition of public accommodations.</p>
<p>Conversely, lakes marked with black dots represent false negatives, or overserviced lakes. These overserviced lakes are those where the model predicted no public services should be present but that are currently are serviced with boat landings, beaches, or parks. These may be examples of lakes whose public services might be considered for decommission or retirement.</p>
<p>Both underserved and overserved lakes are widely distributed throughout the state. This spatial analysis offers a critical bridge between predictive modeling and those audiences who may consume this information as they look to make and implement lake management policy. By identifying specific lakes for which the model’s prediction diverges from current reality, this map serves as a guide for natural resource managers, planners, and local officials for further review.</p>
<section id="limitations-weaknesses" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="limitations-weaknesses"><span class="header-section-number">6.1</span> Limitations + Weaknesses</h2>
<p>Nulla eget cursus ipsum. Vivamus porttitor leo diam, sed volutpat lectus facilisis sit amet. Maecenas et pulvinar metus. Ut at dignissim tellus. In in tincidunt elit. Etiam vulputate lobortis arcu, vel faucibus leo lobortis ac. Aliquam erat volutpat. In interdum orci ac est euismod euismod. Nunc eleifend tristique risus, at lacinia odio commodo in. Sed aliquet ligula odio, sed tempor neque ultricies sit amet.</p>
<p>Etiam quis tortor luctus, pellentesque ante a, finibus dolor. Phasellus in nibh et magna pulvinar malesuada. Ut nisl ex, sagittis at sollicitudin et, sollicitudin id nunc. In id porta urna. Proin porta dolor dolor, vel dapibus nisi lacinia in. Pellentesque ante mauris, ornare non euismod a, fermentum ut sapien. Proin sed vehicula enim. Aliquam tortor odio, vestibulum vitae odio in, tempor molestie justo. Praesent maximus lacus nec leo maximus blandit.</p>
<p>Maecenas turpis velit, ultricies non elementum vel, luctus nec nunc. Nulla a diam interdum, faucibus sapien viverra, finibus metus. Donec non tortor diam. In ut elit aliquet, bibendum sem et, aliquam tortor. Donec congue, sem at rhoncus ultrices, nunc augue cursus erat, quis porttitor mauris libero ut ex. Nullam quis leo urna. Donec faucibus ligula eget pellentesque interdum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean rhoncus interdum erat ut ultricies. Aenean tempus ex non elit suscipit, quis dignissim enim efficitur. Proin laoreet enim massa, vitae laoreet nulla mollis quis.</p>
</section>
<section id="suggestions-for-further-work" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="suggestions-for-further-work"><span class="header-section-number">6.2</span> Suggestions For Further Work</h2>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.</p>
<p>Nunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.</p>
</section>
</section>
<section id="summary-conclusions" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Summary + Conclusions</h1>
<p>Aenean placerat luctus tortor vitae molestie. Nulla at aliquet nulla. Sed efficitur tellus orci, sed fringilla lectus laoreet eget. Vivamus maximus quam sit amet arcu dignissim, sed accumsan massa ullamcorper. Sed iaculis tincidunt feugiat. Nulla in est at nunc ultricies dictum ut vitae nunc. Aenean convallis vel diam at malesuada. Suspendisse arcu libero, vehicula tempus ultrices a, placerat sit amet tortor. Sed dictum id nulla commodo mattis. Aliquam mollis, nunc eu tristique faucibus, purus lacus tincidunt nulla, ac pretium lorem nunc ut enim. Curabitur eget mattis nisl, vitae sodales augue. Nam felis massa, bibendum sit amet nulla vel, vulputate rutrum lacus. Aenean convallis odio pharetra nulla mattis consequat.</p>
<p>Ut ut condimentum augue, nec eleifend nisl. Sed facilisis egestas odio ac pretium. Pellentesque consequat magna sed venenatis sagittis. Vivamus feugiat lobortis magna vitae accumsan. Pellentesque euismod malesuada hendrerit. Ut non mauris non arcu condimentum sodales vitae vitae dolor. Nullam dapibus, velit eget lacinia rutrum, ipsum justo malesuada odio, et lobortis sapien magna vel lacus. Nulla purus neque, hendrerit non malesuada eget, mattis vel erat. Suspendisse potenti.</p>
<p>Nullam dapibus cursus dolor sit amet consequat. Nulla facilisi. Curabitur vel nulla non magna lacinia tincidunt. Duis porttitor quam leo, et blandit velit efficitur ut. Etiam auctor tincidunt porttitor. Phasellus sed accumsan mi. Fusce ut erat dui. Suspendisse eu augue eget turpis condimentum finibus eu non lorem. Donec finibus eros eu ante condimentum, sed pharetra sapien sagittis. Phasellus non dolor ac ante mollis auctor nec et sapien. Pellentesque vulputate at nisi eu tincidunt. Vestibulum at dolor aliquam, hendrerit purus eu, eleifend massa. Morbi consectetur eros id tincidunt gravida. Fusce ut enim quis orci hendrerit lacinia sed vitae enim.</p>
<p>Nulla eget cursus ipsum. Vivamus porttitor leo diam, sed volutpat lectus facilisis sit amet. Maecenas et pulvinar metus. Ut at dignissim tellus. In in tincidunt elit. Etiam vulputate lobortis arcu, vel faucibus leo lobortis ac. Aliquam erat volutpat. In interdum orci ac est euismod euismod. Nunc eleifend tristique risus, at lacinia odio commodo in. Sed aliquet ligula odio, sed tempor neque ultricies sit amet.</p>
</section>
<section id="appendicies" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Appendicies</h1>
<p><strong>Mapping Wisconsin’s Shape and Lake Locations</strong></p>
<p>To generate the maps featured in this analysis, the shape of the state of Wisconsin was retrieved from a public <strong>GeoJSON</strong> file hosted on GitHub. GeoJSON is a geospatial data format based on JSON (JavaScript Object Notation) that stores geographic features such as points, lines, and polygons. In this case, the boundary polygon of Wisconsin serves as the base layer for the map.</p>
<p>The file is read into a <strong>GeoDataFrame</strong> using the <code>GeoPandas</code> library (<code>gpd</code>). GeoPandas is an extension of Pandas that enables spatial operations and plotting by introducing a <code>geometry</code> column capable of storing shapely geometries. A simple function was written to check whether the Wisconsin GeoJSON file already exists locally and, if not, to download and store it from a known remote source.</p>
<p>Lake location data from the Wisconsin Department of Natural Resources (WDNR) was merged with additional columns indicating the presence of public services. Using <code>gpd.points_from_xy()</code>, each lake’s longitude and latitude values were converted to a point geometry, and the data were also cast into a GeoDataFrame.</p>
<p>To ensure proper alignment on the map, both the Wisconsin boundary and the lake point geometries were assigned the same <strong>Coordinate Reference System (CRS)</strong>: EPSG:4326, which corresponds to the standard WGS84 system using degrees of latitude and longitude.</p>
<ul>
<li><p>EPSG:4326 refers to a specific coordinate reference system (CRS) that is widely used for geographic data. It is part of a registry maintained by the European Petroleum Survey Group (EPSG), which assigns numeric codes to standard spatial reference systems. EPSG:4326 specifies that coordinates are expressed in degrees of latitude and longitude, based on the WGS84 datum.</p></li>
<li><p>WGS84, or the World Geodetic System 1984, is a global reference system used by GPS and many mapping applications. It defines the shape of the Earth as an ellipsoid and provides a consistent framework for locating points on the Earth’s surface. When spatial data is aligned to WGS84, it can be accurately mapped and compared across different datasets and tools, making it a common default in global mapping applications and open geospatial data formats.</p></li>
</ul>
<p>Plotting was accomplished using <strong>Matplotlib</strong> and <strong>Seaborn</strong>, with lake points styled according to the presence or absence of public services (e.g., boat landings, beaches, or parks). This overlay provides a spatial perspective that supports both exploratory analysis and the interpretation of model predictions.</p>
</section>
<section id="scratch-space" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Scratch Space</h1>
</section>
<section id="references" class="level1 unnumbered" data-number="10">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">10 References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bendor2013modeling" class="csl-entry" role="listitem">
BenDor, Todd, James Westervelt, Yan Song, and Jared O. Sexton. 2013. <span>“Modeling Park Development Through Regional Land Use Change Simulation.”</span> <em>Land Use Policy</em> 30 (1): 1–12. <a href="https://doi.org/10.1016/j.landusepol.2012.02.001">https://doi.org/10.1016/j.landusepol.2012.02.001</a>.
</div>
<div id="ref-Breiman2001culture" class="csl-entry" role="listitem">
Breiman, Leo. 2001. <span>“Statistical Modeling: The Two Cultures.”</span> <em>Statistical Science</em> 16 (3): 199–215. <a href="http://www.jstor.org/stable/2676681">http://www.jstor.org/stable/2676681</a>.
</div>
<div id="ref-carvalho2024new" class="csl-entry" role="listitem">
Carvalho, J. C. S., T. C. Pimenta, A. C. P. Silverio, M. A. Carvalho, and J. P. C. S. Carvalho. 2024. <span>“A New Data Science Model with Supervised Learning and Its Application on Pesticide Poisoning Diagnosis in Rural Workers.”</span> <em>IEEE Access</em> 12: 40871–82. <a href="https://doi.org/10.1109/access.2024.3375764">https://doi.org/10.1109/access.2024.3375764</a>.
</div>
<div id="ref-Chief2014Engaging" class="csl-entry" role="listitem">
Chief, K., A. M. Meadow, and K. P. Whyte. 2016. <span>“Engaging Southwestern Tribes in Sustainable Water Resources Topics and Management.”</span> <em>Water</em> 8: 350. <a href="https://doi.org/10.3390/w8080350">https://doi.org/10.3390/w8080350</a>.
</div>
<div id="ref-Elbakidz2021hetero" class="csl-entry" role="listitem">
Elbakidze, L., and Q. Beeson. 2021. <span>“State Regulatory Heterogeneity and Compliance with the Clean Water and Safe Drinking Water Acts.”</span> <em>Water Resources Research</em> 57. <a href="https://doi.org/10.1029/2020wr028952">https://doi.org/10.1029/2020wr028952</a>.
</div>
<div id="ref-garn2003why" class="csl-entry" role="listitem">
Garn, Herbert S., John F. Elder, and Dale M. Robertson. 2003. <em>Why Study Lakes?: An Overview of USGS Lake Studies in Wisconsin</em>. Reston, Virginia: U.S. Geological Survey.
</div>
<div id="ref-gutman2021becoming" class="csl-entry" role="listitem">
Gutman, Alex J, and Jordan Goldmeier. 2021. <em>Becoming a Data Head: How to Think, Speak, and Understand Data Science, Statistics, and Machine Learning</em>. John Wiley &amp; Sons.
</div>
<div id="ref-james2023introduction" class="csl-entry" role="listitem">
James, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, and Jonathan Taylor. 2023. <em>An Introduction to Statistical Learning: With Applications in Python</em>. 2023rd ed. Cham, Switzerland: Springer.
</div>
<div id="ref-kretschmann2011citizen" class="csl-entry" role="listitem">
Kretschmann, A., A. Drum, N. L. D. Center, and M. Waters. 2011. <span>“A Citizen Science Program for Monitoring Lake Stages in Northern Wisconsin.”</span> In <em>AGU Fall Meeting Abstracts</em>, 2011:ED23C–0641.
</div>
<div id="ref-lillie1983limnological" class="csl-entry" role="listitem">
Lillie, Richard A., and James W. Mason. 1983. <span>“Limnological Characteristics of Wisconsin Lakes.”</span> Technical Bulletin 138. Madison, Wisconsin: Wisconsin Department of Natural Resources.
</div>
<div id="ref-Martins2021earlyprediction" class="csl-entry" role="listitem">
Martins, M. V., D. Tolledo, J. Machado, L. M. Baptista, and V. Realinho. 2021. <span>“Early Prediction of Student’s Performance in Higher Education: A Case Study.”</span> In <em>Trends and Applications in Information Systems and Technologies: Volume 1 9</em>, 166–75. Springer International Publishing.
</div>
<div id="ref-wisconsin_dnr_lake_modeling_suite" class="csl-entry" role="listitem">
Natural Resources Lake Modeling, Wisconsin Department of. n.d. <span>“Lake Modeling Suite.”</span> <a href="https://dnr.wisconsin.gov/topic/Lakes/Model">https://dnr.wisconsin.gov/topic/Lakes/Model</a>.
</div>
<div id="ref-wisconsin_dnr_swims" class="csl-entry" role="listitem">
Natural Resources SWIMS Pages, Wisconsin Department of. n.d. <span>“Surface Water Integrated Monitoring System (SWIMS).”</span> <a href="https://dnr.wisconsin.gov/topic/SurfaceWater/SWIMS">https://dnr.wisconsin.gov/topic/SurfaceWater/SWIMS</a>.
</div>
<div id="ref-nelson2023confident" class="csl-entry" role="listitem">
Nelson, Adam Ross. 2023. <em>Confident Data Science: Discover the Essential Skills of Data Science</em>. 1st ed. London: Kogan Page.
</div>
<div id="ref-raschka2019python" class="csl-entry" role="listitem">
Raschka, Sebastian, and Vahid Mirjalili. 2019. <em>Python Machine Learning: Machine Learning and Deep Learning with Python, Scikit-Learn, and TensorFlow 2</em>. 3rd ed. Birmingham, UK: Packt Publishing.
</div>
<div id="ref-scikit-learn-cross-validation2023" class="csl-entry" role="listitem">
Scikit-Learn. 2023. <span>“Cross-Validation: Choosing the Best Model.”</span> <a href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation" class="uri">https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation</a>.
</div>
<div id="ref-Spear2020Application" class="csl-entry" role="listitem">
Spear, M. J., H. S. Embke, P. J. Krysan, and M. J. V. Zanden. 2020. <span>“Application of Edna as a Tool for Assessing Fish Population Abundance.”</span> <em>Environmental DNA</em> 3: 83–91. <a href="https://doi.org/10.1002/edn3.94">https://doi.org/10.1002/edn3.94</a>.
</div>
<div id="ref-Thornton2013Stakeholder" class="csl-entry" role="listitem">
Thornton, J. A. 2013. <span>“Stakeholder Participation in Lake Management in Wisconsin (Usa).”</span> <em>Lakes &amp;Amp; Reservoirs: Science, Policy and Management for Sustainable Use</em> 18: 27–33. <a href="https://doi.org/10.1111/lre.12013">https://doi.org/10.1111/lre.12013</a>.
</div>
<div id="ref-Waller2018Ecology" class="csl-entry" role="listitem">
Waller, D. M., and N. J. Reo. 2018. <span>“First Stewards: Ecological Outcomes of Forest and Wildlife Stewardship by Indigenous Peoples of Wisconsin, Usa.”</span> <em>Ecology and Society</em> 23. <a href="https://doi.org/10.5751/es-09865-230145">https://doi.org/10.5751/es-09865-230145</a>.
</div>
<div id="ref-wisconsin_dnr_lake_pages" class="csl-entry" role="listitem">
Wisconsin Department of Natural Resources. 2024. <span>“Wisconsin Department of Natural Resources Lake Pages.”</span> <a href="https://apps.dnr.wi.gov/lakes/lakepages/Results.aspx?advanced=true&amp;wbic=">https://apps.dnr.wi.gov/lakes/lakepages/Results.aspx?advanced=true&amp;wbic=</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>